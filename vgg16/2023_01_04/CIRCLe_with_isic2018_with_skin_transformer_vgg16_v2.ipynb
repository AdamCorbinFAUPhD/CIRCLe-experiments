{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1_HSnGPDTmtQqL19RJaSZ9opYOjST_pFh",
      "authorship_tag": "ABX9TyOQhe8QY/03UMvk4yi4ohvq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamCorbinFAUPhD/CIRCLe-experiments/blob/main/vgg16/2023_01_04/CIRCLe_with_isic2018_with_skin_transformer_vgg16_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment notes:\n",
        "\n",
        "- Vgg16 \n",
        "- Updating learning to be .01 and weight decay to be .01\n",
        "\n",
        "Results: \n",
        "\n",
        "- Didnt seem to change any result when switching learning rante and weight decay"
      ],
      "metadata": {
        "id": "5K9KcPXtTmUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "This notebook is used to modify the implementation of CIRCLe from this paper : [CIRCLe: Color Invariant Representation\n",
        "Learning for Unbiased Classification of Skin\n",
        "Lesions](https://arxiv.org/pdf/2208.13528.pdf)\n",
        "\n",
        "Their github repo is : https://github.com/arezou-pakzad/CIRCLe\n",
        "\n",
        "This paper uses the Fitzpatrick17k dataset which can be obtained here: https://github.com/mattgroh/fitzpatrick17k\n",
        "\n",
        "For these set of experiments we will use the ISIC 2017 dataset from: https://github.com/manideep2510/melanoma_segmentation.git "
      ],
      "metadata": {
        "id": "jCpy2CqVJ-VI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO list\n",
        "\n",
        "1. [X] Download 2018 dataset\n",
        "1. [X] Analize dataset to get Fitzpatrick info. \n",
        "1. [X] Save off Fitzpatrick info data so we dont have to do it every time\n",
        "1. [X] load cached fitzpatrick data\n",
        "1. [X] Create masks uing https://github.com/DebeshJha/2020-CBMS-DoubleU-Net Because Task 3 for 2018 doesnt havent masks. Trick was to get the higher end GPU and ram (12/29/2022)\n",
        "1. [X] Create pytorch dataloader for ISIC 2018 dataset including loading masks, images, diagnossis, fitzpatrick type for training (12/30/2022) needed to create custom split function\n",
        "1. [X] Create dataloaders for test and validation  (12/30/2022)\n",
        "1. [X] Added jupiter notebook download code into the github repo (1/1/2023)\n",
        "1. [X] plug in dataloader into CIRCLe main file (1/1/2023)\n",
        "1. [X] Figure out how to transform image and mask the same from the dataloader (1/2/2023)\n",
        "1. [X] Use the new dataloader to train the model (1/2/2023)\n",
        "1. [X] Use new transformer for CIRCLe model (1/3/2023)\n",
        "1. [ ] test using different base models\n",
        "1. [ ] test that adding dropout might help with overfitting\n",
        "1. [ ] Add more metrics such as precision and recall\n",
        "1. [ ] add fairness metrics\n",
        "1. [ ] add confusion matrics\n",
        "1. [ ] add sensitivity and specificity\n",
        "1. [ ] add metrics for each class\n",
        "1. [ ] (optional) Go back and download and use larger datasets\n",
        "1. [ ] (optional) Run Fitzpatrick on larger datasets(currently using the test set from isic 2018 task 3)\n",
        "1. [ ] The dataloaders need to be split stratified different than the current \"training, validation, and test\" as given from https://challenge.isic-archive.com/data/#2018 based on skin types. 12/30/2022 - I think this is done BUT we might consider doing k-fold approach which adds another layer of complexity to the dataloaders"
      ],
      "metadata": {
        "id": "ajchIOEXMH4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the environment"
      ],
      "metadata": {
        "id": "1IqTnocWPMkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "DATASET_USED = \"ISIC_2018\"  # ISIC_2017_ORIG, ISIC_2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX3pAmwlWnf5",
        "outputId": "3d495fe2-aaab-4fe5-ea53-e79f1410e848"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs & imports"
      ],
      "metadata": {
        "id": "yzsWv7g9MB87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import torch\n",
        "\n",
        "from enum import Enum\n",
        "import io\n",
        "import math\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import skimage\n",
        "from skimage import color, util\n",
        "\n",
        "import PIL\n",
        "from PIL import ImageStat\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "\n",
        "import cv2\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import glob\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.metrics import *\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "ylyPAeA2lHbM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download latest code"
      ],
      "metadata": {
        "id": "cLWa0BAdPQBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kQ5LposJzeZ",
        "outputId": "5316ffea-e908-46a1-9b98-f2018d098e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CIRCLe' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/acorbin3/CIRCLe.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./CIRCLe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9eGp7LOm90J",
        "outputId": "828a1edd-55fa-40f7-9fcb-be550ceb70ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CIRCLe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- models/circle.py"
      ],
      "metadata": {
        "id": "OgCG317Q6qru"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNNuLRyKQ7-",
        "outputId": "1687df24-0d84-452e-86f1-a3b78283ae2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r ./requirements.txt"
      ],
      "metadata": {
        "id": "DWzYtBAIKvuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9e2f3a-e84b-4cd8-cfa7-3486ae9fc35f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.23.2 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 1)) (1.23.2)\n",
            "Requirement already satisfied: pandas==1.4.4 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: Pillow==9.2.0 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 3)) (9.2.0)\n",
            "Requirement already satisfied: scikit_learn==1.1.2 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: tensorflow==2.9.2 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 5)) (2.9.2)\n",
            "Collecting torch==1.12.1\n",
            "  Using cached torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "Collecting torchvision==0.13.1\n",
            "  Using cached torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
            "Requirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 8)) (4.64.1)\n",
            "Requirement already satisfied: derm-ita>=0.0.8 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 9)) (0.0.8)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.10.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.51.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.29.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (21.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.19.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.25.1)\n",
            "Requirement already satisfied: patchify>=0.2.3 in /usr/local/lib/python3.8/dist-packages (from derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (0.2.3)\n",
            "Requirement already satisfied: scikit-image>=0.19 in /usr/local/lib/python3.8/dist-packages (from derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (0.19.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.38.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2022.10.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2.8.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.2.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu111\n",
            "    Uninstalling torchvision-0.10.0+cu111:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 0.9.0 requires torch==1.9.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.12.1 torchvision-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This next block of code will be needed if you get this error: **\n",
        "\n",
        "A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation. The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70."
      ],
      "metadata": {
        "id": "1q3ovxukTHlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "qhckJLuHSlkS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IF ERROR, RESTART RUNTIME due to derm-ita lib\n",
        "This is due to derm-ita using newer libaries than the Google Colab default(during this time of 12/24/2022)"
      ],
      "metadata": {
        "id": "pB8smeonMesX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train CIRCLe model "
      ],
      "metadata": {
        "id": "fKUV22LhVzBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir ./saved\n",
        "%mkdir ./saved/model"
      ],
      "metadata": {
        "id": "08ngcZp9m1-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf05123-3422-4d97-ccbe-ce03c819f012"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘./saved’: File exists\n",
            "mkdir: cannot create directory ‘./saved/model’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akY1e2Sh-FdU",
        "outputId": "791152e3-7367-45f9-b1f2-4574d147e4a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --use_reg_loss True --base vgg16 --dataset isic2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH5FKsbclkje",
        "outputId": "46e5409f-521e-4c58-aa2e-ab5cb9570a4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flags:\n",
            "\talpha: 0.1\n",
            "\tbase: vgg16\n",
            "\tbatch_size: 32\n",
            "\tdata_dir: ../data/fitz17k/images/all/\n",
            "\tdataset: isic2018\n",
            "\tepochs: 100\n",
            "\tgan_path: saved/stargan/\n",
            "\thidden_dim: 256\n",
            "\tlr: 0.01\n",
            "\tmodel: circle\n",
            "\tmodel_save_dir: saved/model/\n",
            "\tnum_classes: 7\n",
            "\tseed: 1\n",
            "\tuse_reg_loss: True\n",
            "\tweight_decay: 0.01\n",
            "isic2018 images already downloaded\n",
            "isic 2018 masks already downladed\n",
            "Donloading isic 2018 ground truth classification data\n",
            "Creating dataframe\n",
            "\t Looking for cached dataframe\n",
            "\t\t organize_data/isic_2018/saved_data_2022_12_27_isic_2018.csv\n",
            "Creating dataframe. Complete!\n",
            "Splitting up the dataset into train,test, validation datasets\n",
            "fizpatrick_skin_type: 1 8001\n",
            "\t train 6400\n",
            "\t test 800\n",
            "\t val 801\n",
            "fizpatrick_skin_type: 2 1049\n",
            "\t train 839\n",
            "\t test 105\n",
            "\t val 105\n",
            "fizpatrick_skin_type: 3 513\n",
            "\t train 410\n",
            "\t test 51\n",
            "\t val 52\n",
            "fizpatrick_skin_type: 4 182\n",
            "\t train 145\n",
            "\t test 18\n",
            "\t val 19\n",
            "fizpatrick_skin_type: 5 107\n",
            "\t train 85\n",
            "\t test 11\n",
            "\t val 11\n",
            "fizpatrick_skin_type: 6 163\n",
            "\t train 130\n",
            "\t test 16\n",
            "\t val 17\n",
            "total_train: 8009 79.9700449326011\n",
            "total_test: 1001 9.995007488766849\n",
            "total_val: 1005 10.034947578632051\n",
            "train size: 8009\n",
            "test size: 1001\n",
            "val size: 1005\n",
            "\ttrain: skin type 1 : 6400\n",
            "\ttrain: skin type 2 : 839\n",
            "\ttrain: skin type 3 : 410\n",
            "\ttrain: skin type 4 : 145\n",
            "\ttrain: skin type 5 : 85\n",
            "\ttrain: skin type 6 : 130\n",
            "----\n",
            "\ttest: skin type 1 : 800\n",
            "\ttest: skin type 2 : 105\n",
            "\ttest: skin type 3 : 51\n",
            "\ttest: skin type 4 : 18\n",
            "\ttest: skin type 5 : 11\n",
            "\ttest: skin type 6 : 16\n",
            "----\n",
            "\tval: skin type 1 : 801\n",
            "\tval: skin type 2 : 105\n",
            "\tval: skin type 3 : 52\n",
            "\tval: skin type 4 : 19\n",
            "\tval: skin type 5 : 11\n",
            "\tval: skin type 6 : 17\n",
            "train size: 8009\n",
            "val size: 1005\n",
            "train skin types: [1 2 3 4 5 6]\n",
            "val skin types: [1 2 3 4 5 6]\n",
            "train skin conditions: 7\n",
            "val skin conditions: 7\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 0: Best val loss inf, Best val acc 0.0\n",
            ">>> Training: Loss 1.164, Reg 0.002, Acc 0.664, precision: 0.664, recall0.664\n",
            ">>> Val: Loss 1.153, Reg 0.000, Acc 0.662, precision: 0.662, recall0.662\n",
            "Saved model with highest acc ...\n",
            "Epoch 1: Best val loss inf, Best val acc 0.6622983870967742\n",
            ">>> Training: Loss 1.135, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.170, Reg 0.000, Acc 0.662, precision: 0.662, recall0.662\n",
            "Epoch 2: Best val loss inf, Best val acc 0.6622983870967742\n",
            ">>> Training: Loss 1.131, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.177, Reg 0.000, Acc 0.662, precision: 0.662, recall0.662\n",
            "Epoch 3: Best val loss inf, Best val acc 0.6622983870967742\n",
            ">>> Training: Loss 1.129, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.192, Reg 0.000, Acc 0.662, precision: 0.662, recall0.662\n",
            "Epoch 4: Best val loss inf, Best val acc 0.6622983870967742\n",
            ">>> Training: Loss 1.130, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.214, Reg 0.000, Acc 0.661, precision: 0.661, recall0.661\n",
            "Epoch 5: Best val loss inf, Best val acc 0.6622983870967742\n",
            ">>> Training: Loss 1.130, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.225, Reg 0.000, Acc 0.661, precision: 0.661, recall0.661\n",
            "Epoch 6: Best val loss inf, Best val acc 0.6622983870967742\n",
            ">>> Training: Loss 1.129, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.215, Reg 0.000, Acc 0.664, precision: 0.664, recall0.664\n",
            "Saved model with highest acc ...\n",
            "Epoch 7: Best val loss inf, Best val acc 0.6643145161290323\n",
            ">>> Training: Loss 1.128, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.212, Reg 0.000, Acc 0.665, precision: 0.665, recall0.665\n",
            "Saved model with highest acc ...\n",
            "Epoch 8: Best val loss inf, Best val acc 0.6653225806451613\n",
            ">>> Training: Loss 1.128, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.219, Reg 0.000, Acc 0.663, precision: 0.663, recall0.663\n",
            "Epoch 9: Best val loss inf, Best val acc 0.6653225806451613\n",
            ">>> Training: Loss 1.128, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.220, Reg 0.000, Acc 0.663, precision: 0.663, recall0.663\n",
            "Epoch 10: Best val loss inf, Best val acc 0.6653225806451613\n",
            ">>> Training: Loss 1.128, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.223, Reg 0.000, Acc 0.662, precision: 0.662, recall0.662\n",
            "Epoch 11: Best val loss inf, Best val acc 0.6653225806451613\n",
            ">>> Training: Loss 1.128, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.223, Reg 0.000, Acc 0.663, precision: 0.663, recall0.663\n",
            "Epoch 12: Best val loss inf, Best val acc 0.6653225806451613\n",
            ">>> Training: Loss 1.128, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.216, Reg 0.000, Acc 0.664, precision: 0.664, recall0.664\n",
            "Epoch 13: Best val loss inf, Best val acc 0.6653225806451613\n",
            ">>> Training: Loss 1.128, Reg 0.000, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.224, Reg 0.000, Acc 0.662, precision: 0.662, recall0.662\n",
            "Epoch 14: Best val loss inf, Best val acc 0.6653225806451613\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 103, in <module>\n",
            "    for data in tqdm(train_loader, ncols=75, leave=False):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tqdm/std.py\", line 1195, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 681, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 721, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/CIRCLe/organize_data/isic_2018/dataset.py\", line 52, in __getitem__\n",
            "    image, mask = self.transform(image, mask)\n",
            "  File \"/content/CIRCLe/organize_data/transforms.py\", line 30, in __call__\n",
            "    image, target = t(image, target)\n",
            "  File \"/content/CIRCLe/organize_data/transforms.py\", line 39, in __call__\n",
            "    image = F.resize(image, self.size)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\", line 430, in resize\n",
            "    return F_pil.resize(img, size=size, interpolation=pil_interpolation, max_size=max_size)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_pil.py\", line 282, in resize\n",
            "    return img.resize(size[::-1], interpolation)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2046, in resize\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 257, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%mkdir /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints"
      ],
      "metadata": {
        "id": "O4m8fvzN-oJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f045fc50-ebd8-484f-b41d-f3391246a5d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints’: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cp ./saved/model/epoch97_acc_0.762.ckpt /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints/CIRCLE/mobilenetv3l/"
      ],
      "metadata": {
        "id": "1hFw2rQB-7np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc2f444a-6bed-4732-ce97-2fb4991a531e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat './saved/model/epoch97_acc_0.762.ckpt': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}