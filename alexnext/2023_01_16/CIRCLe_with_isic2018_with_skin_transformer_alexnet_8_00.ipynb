{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_HSnGPDTmtQqL19RJaSZ9opYOjST_pFh",
      "authorship_tag": "ABX9TyN46Hl61BjvwLuwv9tmOzNX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamCorbinFAUPhD/CIRCLe-experiments/blob/main/alexnext/2023_01_16/CIRCLe_with_isic2018_with_skin_transformer_alexnet_8_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment notes\n",
        "\n",
        "- date: 2023/01/16 8am\n",
        "- base model: alexnet\n",
        "- updating to calculate the normalization.\n",
        "\n",
        "\n",
        "Results: \n",
        "-  didnt seem like it helped much\n"
      ],
      "metadata": {
        "id": "5K9KcPXtTmUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "This notebook is used to modify the implementation of CIRCLe from this paper : [CIRCLe: Color Invariant Representation\n",
        "Learning for Unbiased Classification of Skin\n",
        "Lesions](https://arxiv.org/pdf/2208.13528.pdf)\n",
        "\n",
        "Their github repo is : https://github.com/arezou-pakzad/CIRCLe\n",
        "\n",
        "This paper uses the Fitzpatrick17k dataset which can be obtained here: https://github.com/mattgroh/fitzpatrick17k\n",
        "\n",
        "For these set of experiments we will use the ISIC 2017 dataset from: https://github.com/manideep2510/melanoma_segmentation.git "
      ],
      "metadata": {
        "id": "jCpy2CqVJ-VI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO list\n",
        "\n",
        "1. [X] Download 2018 dataset\n",
        "1. [X] Analize dataset to get Fitzpatrick info. \n",
        "1. [X] Save off Fitzpatrick info data so we dont have to do it every time\n",
        "1. [X] load cached fitzpatrick data\n",
        "1. [X] Create masks uing https://github.com/DebeshJha/2020-CBMS-DoubleU-Net Because Task 3 for 2018 doesnt havent masks. Trick was to get the higher end GPU and ram (12/29/2022)\n",
        "1. [X] Create pytorch dataloader for ISIC 2018 dataset including loading masks, images, diagnossis, fitzpatrick type for training (12/30/2022) needed to create custom split function\n",
        "1. [X] Create dataloaders for test and validation  (12/30/2022)\n",
        "1. [X] Added jupiter notebook download code into the github repo (1/1/2023)\n",
        "1. [X] plug in dataloader into CIRCLe main file (1/1/2023)\n",
        "1. [X] Figure out how to transform image and mask the same from the dataloader (1/2/2023)\n",
        "1. [X] Use the new dataloader to train the model (1/2/2023)\n",
        "1. [X] Use new transformer for CIRCLe model (1/3/2023)\n",
        "1. [ ] test using different base models\n",
        "1. [ ] test that adding dropout might help with overfitting\n",
        "1. [X] Add more metrics such as precision and recall (1/4/2023)\n",
        "1. [ ] add fairness metrics\n",
        "1. [ ] add confusion matrics\n",
        "1. [ ] add sensitivity and specificity\n",
        "1. [ ] add metrics for each class\n",
        "1. [ ] (optional) Go back and download and use larger datasets\n",
        "1. [ ] (optional) Run Fitzpatrick on larger datasets(currently using the test set from isic 2018 task 3)\n",
        "1. [ ] The dataloaders need to be split stratified different than the current \"training, validation, and test\" as given from https://challenge.isic-archive.com/data/#2018 based on skin types. 12/30/2022 - I think this is done BUT we might consider doing k-fold approach which adds another layer of complexity to the dataloaders"
      ],
      "metadata": {
        "id": "ajchIOEXMH4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the environment"
      ],
      "metadata": {
        "id": "1IqTnocWPMkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX3pAmwlWnf5",
        "outputId": "495f31e8-7161-4f78-c386-3c9f949517ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs & imports"
      ],
      "metadata": {
        "id": "yzsWv7g9MB87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download latest code"
      ],
      "metadata": {
        "id": "cLWa0BAdPQBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kQ5LposJzeZ",
        "outputId": "2164faa6-d5bc-4a13-9299-eeb21d10c191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CIRCLe'...\n",
            "remote: Enumerating objects: 491, done.\u001b[K\n",
            "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 491 (delta 83), reused 116 (delta 51), pack-reused 339\u001b[K\n",
            "Receiving objects: 100% (491/491), 1.81 MiB | 19.52 MiB/s, done.\n",
            "Resolving deltas: 100% (249/249), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/acorbin3/CIRCLe.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./CIRCLe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9eGp7LOm90J",
        "outputId": "ae318e44-7ccc-4710-881d-34d4c8ffee79"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CIRCLe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- models/circle.py"
      ],
      "metadata": {
        "id": "OgCG317Q6qru"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNNuLRyKQ7-",
        "outputId": "4b39dac9-bf4e-44e7-e3a8-a3abfdd2f2be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r ./requirements.txt"
      ],
      "metadata": {
        "id": "DWzYtBAIKvuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b6168a-f43e-4645-ae6b-82d094a0d092"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23.2\n",
            "  Downloading numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.4.4\n",
            "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.2.0\n",
            "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==1.1.2\n",
            "  Downloading scikit_learn-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow==2.9.2 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 5)) (2.9.2)\n",
            "Collecting torch==1.12.1\n",
            "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.1\n",
            "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 8)) (4.64.1)\n",
            "Collecting derm-ita>=0.0.8\n",
            "  Downloading derm_ita-0.0.8-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2022.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.51.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.19.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (21.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.29.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (14.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.25.1)\n",
            "Collecting patchify>=0.2.3\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Collecting scikit-image>=0.19\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.38.4)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2.8.8)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2022.10.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.0.9)\n",
            "Collecting scipy>=1.3.2\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.2.2)\n",
            "Installing collected packages: torch, Pillow, numpy, torchvision, scipy, patchify, pandas, scikit_learn, scikit-image, derm-ita\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.2.0 derm-ita-0.0.8 numpy-1.23.2 pandas-1.4.4 patchify-0.2.3 scikit-image-0.19.3 scikit_learn-1.1.2 scipy-1.10.0 torch-1.12.1 torchvision-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This next block of code will be needed if you get this error: **\n",
        "\n",
        "A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation. The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70."
      ],
      "metadata": {
        "id": "1q3ovxukTHlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "qhckJLuHSlkS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IF ERROR, RESTART RUNTIME due to derm-ita lib\n",
        "This is due to derm-ita using newer libaries than the Google Colab default(during this time of 12/24/2022)"
      ],
      "metadata": {
        "id": "pB8smeonMesX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train CIRCLe model "
      ],
      "metadata": {
        "id": "fKUV22LhVzBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir ./saved\n",
        "%mkdir ./saved/model"
      ],
      "metadata": {
        "id": "08ngcZp9m1-S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- main.py\n",
        "!git checkout -- organize_data/isic_2018/dataset.py"
      ],
      "metadata": {
        "id": "y8uJMyX54Qti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "akY1e2Sh-FdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --use_reg_loss False --base alexnet --dataset isic2018 --hidden_dim 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH5FKsbclkje",
        "outputId": "e54a667d-f239-4a33-d12a-5e4a0d4dc833"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flags:\n",
            "\talpha: 0.1\n",
            "\tbase: alexnet\n",
            "\tbatch_size: 32\n",
            "\tdata_dir: ../data/fitz17k/images/all/\n",
            "\tdataset: isic2018\n",
            "\tepochs: 100\n",
            "\tgan_path: saved/stargan/\n",
            "\thidden_dim: 16\n",
            "\tlr: 0.001\n",
            "\tmodel: circle\n",
            "\tmodel_save_dir: saved/model/\n",
            "\tnum_classes: 7\n",
            "\tseed: 1\n",
            "\tuse_reg_loss: True\n",
            "\tweight_decay: 0.001\n",
            "isic2018 images already downloaded\n",
            "isic 2018 masks already downladed\n",
            "Donloading isic 2018 ground truth classification data\n",
            "Creating dataframe\n",
            "\t Looking for cached dataframe\n",
            "\t\t organize_data/isic_2018/saved_data_2022_12_27_isic_2018.csv\n",
            "Creating dataframe. Complete!\n",
            "Splitting up the dataset into train,test, validation datasets based on the skin condition\n",
            "fizpatrick_skin_type: ('AKIEC', 1) 291\n",
            "\t train 232\n",
            "\t test 29\n",
            "\t val 30\n",
            "fizpatrick_skin_type: ('AKIEC', 2) 29\n",
            "\t train 23\n",
            "\t test 3\n",
            "\t val 3\n",
            "fizpatrick_skin_type: ('AKIEC', 3) 4\n",
            "\t train 3\n",
            "\t test 1\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('AKIEC', 4) 1\n",
            "\t train 3\n",
            "\t test 0\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('AKIEC', 6) 2\n",
            "\t train 1\n",
            "\t test 1\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('BCC', 1) 464\n",
            "\t train 371\n",
            "\t test 46\n",
            "\t val 47\n",
            "fizpatrick_skin_type: ('BCC', 2) 35\n",
            "\t train 28\n",
            "\t test 3\n",
            "\t val 4\n",
            "fizpatrick_skin_type: ('BCC', 3) 9\n",
            "\t train 7\n",
            "\t test 1\n",
            "\t val 1\n",
            "fizpatrick_skin_type: ('BCC', 4) 1\n",
            "\t train 7\n",
            "\t test 0\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('BCC', 5) 2\n",
            "\t train 1\n",
            "\t test 1\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('BCC', 6) 3\n",
            "\t train 2\n",
            "\t test 1\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('BKL', 1) 991\n",
            "\t train 792\n",
            "\t test 99\n",
            "\t val 100\n",
            "fizpatrick_skin_type: ('BKL', 2) 55\n",
            "\t train 44\n",
            "\t test 5\n",
            "\t val 6\n",
            "fizpatrick_skin_type: ('BKL', 3) 12\n",
            "\t train 9\n",
            "\t test 1\n",
            "\t val 2\n",
            "fizpatrick_skin_type: ('BKL', 4) 13\n",
            "\t train 10\n",
            "\t test 1\n",
            "\t val 2\n",
            "fizpatrick_skin_type: ('BKL', 5) 7\n",
            "\t train 5\n",
            "\t test 1\n",
            "\t val 1\n",
            "fizpatrick_skin_type: ('BKL', 6) 21\n",
            "\t train 16\n",
            "\t test 2\n",
            "\t val 3\n",
            "fizpatrick_skin_type: ('DF', 1) 107\n",
            "\t train 85\n",
            "\t test 11\n",
            "\t val 11\n",
            "fizpatrick_skin_type: ('DF', 2) 3\n",
            "\t train 2\n",
            "\t test 1\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('DF', 3) 4\n",
            "\t train 3\n",
            "\t test 1\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('DF', 5) 1\n",
            "\t train 3\n",
            "\t test 0\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('MEL', 1) 993\n",
            "\t train 794\n",
            "\t test 99\n",
            "\t val 100\n",
            "fizpatrick_skin_type: ('MEL', 2) 53\n",
            "\t train 42\n",
            "\t test 5\n",
            "\t val 6\n",
            "fizpatrick_skin_type: ('MEL', 3) 31\n",
            "\t train 24\n",
            "\t test 3\n",
            "\t val 4\n",
            "fizpatrick_skin_type: ('MEL', 4) 8\n",
            "\t train 6\n",
            "\t test 1\n",
            "\t val 1\n",
            "fizpatrick_skin_type: ('MEL', 5) 9\n",
            "\t train 7\n",
            "\t test 1\n",
            "\t val 1\n",
            "fizpatrick_skin_type: ('MEL', 6) 19\n",
            "\t train 15\n",
            "\t test 2\n",
            "\t val 2\n",
            "fizpatrick_skin_type: ('NV', 1) 5021\n",
            "\t train 4016\n",
            "\t test 502\n",
            "\t val 503\n",
            "fizpatrick_skin_type: ('NV', 2) 870\n",
            "\t train 696\n",
            "\t test 87\n",
            "\t val 87\n",
            "fizpatrick_skin_type: ('NV', 3) 451\n",
            "\t train 360\n",
            "\t test 45\n",
            "\t val 46\n",
            "fizpatrick_skin_type: ('NV', 4) 159\n",
            "\t train 127\n",
            "\t test 16\n",
            "\t val 16\n",
            "fizpatrick_skin_type: ('NV', 5) 87\n",
            "\t train 69\n",
            "\t test 9\n",
            "\t val 9\n",
            "fizpatrick_skin_type: ('NV', 6) 117\n",
            "\t train 93\n",
            "\t test 12\n",
            "\t val 12\n",
            "fizpatrick_skin_type: ('VASC', 1) 134\n",
            "\t train 107\n",
            "\t test 13\n",
            "\t val 14\n",
            "fizpatrick_skin_type: ('VASC', 2) 4\n",
            "\t train 3\n",
            "\t test 1\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('VASC', 3) 2\n",
            "\t train 1\n",
            "\t test 1\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('VASC', 5) 1\n",
            "\t train 1\n",
            "\t test 0\n",
            "\t val 0\n",
            "fizpatrick_skin_type: ('VASC', 6) 1\n",
            "\t train 1\n",
            "\t test 0\n",
            "\t val 0\n",
            "total_train: 7999 79.8701947079381\n",
            "total_test: 1005 10.034947578632051\n",
            "total_val: 1011 10.094857713429855\n",
            "train size: 7999\n",
            "test size: 1005\n",
            "val size: 1011\n",
            "dataset sizes:10015. df size: 10015\n",
            "----\n",
            "\ttrain: skin type 1 : 6397 (79.97)\n",
            "\t\tNV: 5361 (83.80)\n",
            "\t\tBKL: 876 (13.69)\n",
            "\t\tMEL: 888 (13.88)\n",
            "\t\tAKIEC: 260 (4.06)\n",
            "\t\tBCC: 410 (6.41)\n",
            "\t\tVASC: 113 (1.77)\n",
            "\t\tDF: 91 (1.42)\n",
            "\ttrain: skin type 2 : 838 (10.48)\n",
            "\t\tNV: 5361 (639.74)\n",
            "\t\tBKL: 876 (104.53)\n",
            "\t\tMEL: 888 (105.97)\n",
            "\t\tAKIEC: 260 (31.03)\n",
            "\t\tBCC: 410 (48.93)\n",
            "\t\tVASC: 113 (13.48)\n",
            "\t\tDF: 91 (10.86)\n",
            "\ttrain: skin type 3 : 407 (5.09)\n",
            "\t\tNV: 5361 (1317.20)\n",
            "\t\tBKL: 876 (215.23)\n",
            "\t\tMEL: 888 (218.18)\n",
            "\t\tAKIEC: 260 (63.88)\n",
            "\t\tBCC: 410 (100.74)\n",
            "\t\tVASC: 113 (27.76)\n",
            "\t\tDF: 91 (22.36)\n",
            "\ttrain: skin type 4 : 145 (1.81)\n",
            "\t\tNV: 5361 (3697.24)\n",
            "\t\tBKL: 876 (604.14)\n",
            "\t\tMEL: 888 (612.41)\n",
            "\t\tAKIEC: 260 (179.31)\n",
            "\t\tBCC: 410 (282.76)\n",
            "\t\tVASC: 113 (77.93)\n",
            "\t\tDF: 91 (62.76)\n",
            "\ttrain: skin type 5 : 84 (1.05)\n",
            "\t\tNV: 5361 (6382.14)\n",
            "\t\tBKL: 876 (1042.86)\n",
            "\t\tMEL: 888 (1057.14)\n",
            "\t\tAKIEC: 260 (309.52)\n",
            "\t\tBCC: 410 (488.10)\n",
            "\t\tVASC: 113 (134.52)\n",
            "\t\tDF: 91 (108.33)\n",
            "\ttrain: skin type 6 : 128 (1.60)\n",
            "\t\tNV: 5361 (4188.28)\n",
            "\t\tBKL: 876 (684.38)\n",
            "\t\tMEL: 888 (693.75)\n",
            "\t\tAKIEC: 260 (203.12)\n",
            "\t\tBCC: 410 (320.31)\n",
            "\t\tVASC: 113 (88.28)\n",
            "\t\tDF: 91 (71.09)\n",
            "----\n",
            "\ttrain: skin type 1 : 799 (79.50)\n",
            "\t\tNV: 671 (83.98)\n",
            "\t\tBKL: 109 (13.64)\n",
            "\t\tMEL: 111 (13.89)\n",
            "\t\tAKIEC: 34 (4.26)\n",
            "\t\tBCC: 52 (6.51)\n",
            "\t\tVASC: 15 (1.88)\n",
            "\t\tDF: 13 (1.63)\n",
            "\ttrain: skin type 2 : 105 (10.45)\n",
            "\t\tNV: 671 (639.05)\n",
            "\t\tBKL: 109 (103.81)\n",
            "\t\tMEL: 111 (105.71)\n",
            "\t\tAKIEC: 34 (32.38)\n",
            "\t\tBCC: 52 (49.52)\n",
            "\t\tVASC: 15 (14.29)\n",
            "\t\tDF: 13 (12.38)\n",
            "\ttrain: skin type 3 : 53 (5.27)\n",
            "\t\tNV: 671 (1266.04)\n",
            "\t\tBKL: 109 (205.66)\n",
            "\t\tMEL: 111 (209.43)\n",
            "\t\tAKIEC: 34 (64.15)\n",
            "\t\tBCC: 52 (98.11)\n",
            "\t\tVASC: 15 (28.30)\n",
            "\t\tDF: 13 (24.53)\n",
            "\ttrain: skin type 4 : 18 (1.79)\n",
            "\t\tNV: 671 (3727.78)\n",
            "\t\tBKL: 109 (605.56)\n",
            "\t\tMEL: 111 (616.67)\n",
            "\t\tAKIEC: 34 (188.89)\n",
            "\t\tBCC: 52 (288.89)\n",
            "\t\tVASC: 15 (83.33)\n",
            "\t\tDF: 13 (72.22)\n",
            "\ttrain: skin type 5 : 12 (1.19)\n",
            "\t\tNV: 671 (5591.67)\n",
            "\t\tBKL: 109 (908.33)\n",
            "\t\tMEL: 111 (925.00)\n",
            "\t\tAKIEC: 34 (283.33)\n",
            "\t\tBCC: 52 (433.33)\n",
            "\t\tVASC: 15 (125.00)\n",
            "\t\tDF: 13 (108.33)\n",
            "\ttrain: skin type 6 : 18 (1.79)\n",
            "\t\tNV: 671 (3727.78)\n",
            "\t\tBKL: 109 (605.56)\n",
            "\t\tMEL: 111 (616.67)\n",
            "\t\tAKIEC: 34 (188.89)\n",
            "\t\tBCC: 52 (288.89)\n",
            "\t\tVASC: 15 (83.33)\n",
            "\t\tDF: 13 (72.22)\n",
            "----\n",
            "\ttrain: skin type 1 : 805 (79.62)\n",
            "\t\tNV: 673 (83.60)\n",
            "\t\tBKL: 114 (14.16)\n",
            "\t\tMEL: 114 (14.16)\n",
            "\t\tAKIEC: 33 (4.10)\n",
            "\t\tBCC: 52 (6.46)\n",
            "\t\tVASC: 14 (1.74)\n",
            "\t\tDF: 11 (1.37)\n",
            "\ttrain: skin type 2 : 106 (10.48)\n",
            "\t\tNV: 673 (634.91)\n",
            "\t\tBKL: 114 (107.55)\n",
            "\t\tMEL: 114 (107.55)\n",
            "\t\tAKIEC: 33 (31.13)\n",
            "\t\tBCC: 52 (49.06)\n",
            "\t\tVASC: 14 (13.21)\n",
            "\t\tDF: 11 (10.38)\n",
            "\ttrain: skin type 3 : 53 (5.24)\n",
            "\t\tNV: 673 (1269.81)\n",
            "\t\tBKL: 114 (215.09)\n",
            "\t\tMEL: 114 (215.09)\n",
            "\t\tAKIEC: 33 (62.26)\n",
            "\t\tBCC: 52 (98.11)\n",
            "\t\tVASC: 14 (26.42)\n",
            "\t\tDF: 11 (20.75)\n",
            "\ttrain: skin type 4 : 19 (1.88)\n",
            "\t\tNV: 673 (3542.11)\n",
            "\t\tBKL: 114 (600.00)\n",
            "\t\tMEL: 114 (600.00)\n",
            "\t\tAKIEC: 33 (173.68)\n",
            "\t\tBCC: 52 (273.68)\n",
            "\t\tVASC: 14 (73.68)\n",
            "\t\tDF: 11 (57.89)\n",
            "\ttrain: skin type 5 : 11 (1.09)\n",
            "\t\tNV: 673 (6118.18)\n",
            "\t\tBKL: 114 (1036.36)\n",
            "\t\tMEL: 114 (1036.36)\n",
            "\t\tAKIEC: 33 (300.00)\n",
            "\t\tBCC: 52 (472.73)\n",
            "\t\tVASC: 14 (127.27)\n",
            "\t\tDF: 11 (100.00)\n",
            "\ttrain: skin type 6 : 17 (1.68)\n",
            "\t\tNV: 673 (3958.82)\n",
            "\t\tBKL: 114 (670.59)\n",
            "\t\tMEL: 114 (670.59)\n",
            "\t\tAKIEC: 33 (194.12)\n",
            "\t\tBCC: 52 (305.88)\n",
            "\t\tVASC: 14 (82.35)\n",
            "\t\tDF: 11 (64.71)\n",
            "train size: 7999\n",
            "val size: 1011\n",
            "train skin types: [1 2 3 4 6 5]\n",
            "val skin types: [1 2 3 4 5 6]\n",
            "train skin conditions: 7\n",
            "val skin conditions: 7\n",
            "(128, 128, 3, 10015)\n",
            "tcmalloc: large alloc 1969029120 bytes == 0x43552000 @  0x7f99a13a61e7 0x7f994cb80064 0x7f994cb807ff 0x7f994cbdefc5 0x7f994cbe1c01 0x7f994cc74d87 0x4f781f 0x4997a2 0x5d8868 0x4990ca 0x55cd91 0x5d8941 0x4990ca 0x55cd91 0x55d743 0x642630 0x6426ae 0x644b78 0x64511c 0x677e5e 0x678029 0x7f99a0fa3c87 0x5e1baa\n",
            "normMean = [0.76307946, 0.54567814, 0.57007694]\n",
            "normStd = [0.14093567, 0.15261906, 0.16997448]\n",
            "normMean [0.76307946, 0.54567814, 0.57007694], normStd [0.14093567, 0.15261906, 0.16997448]\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100% 233M/233M [00:00<00:00, 270MB/s]\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 31, 31]          23,296\n",
            "              ReLU-2           [-1, 64, 31, 31]               0\n",
            "         MaxPool2d-3           [-1, 64, 15, 15]               0\n",
            "            Conv2d-4          [-1, 192, 15, 15]         307,392\n",
            "              ReLU-5          [-1, 192, 15, 15]               0\n",
            "         MaxPool2d-6            [-1, 192, 7, 7]               0\n",
            "            Conv2d-7            [-1, 384, 7, 7]         663,936\n",
            "              ReLU-8            [-1, 384, 7, 7]               0\n",
            "            Conv2d-9            [-1, 256, 7, 7]         884,992\n",
            "             ReLU-10            [-1, 256, 7, 7]               0\n",
            "           Conv2d-11            [-1, 256, 7, 7]         590,080\n",
            "             ReLU-12            [-1, 256, 7, 7]               0\n",
            "        MaxPool2d-13            [-1, 256, 3, 3]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 16]          65,552\n",
            "          AlexNet-22                   [-1, 16]               0\n",
            "           Linear-23                    [-1, 7]             119\n",
            "================================================================\n",
            "Total params: 57,069,511\n",
            "Trainable params: 57,069,511\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 2.76\n",
            "Params size (MB): 217.70\n",
            "Estimated Total Size (MB): 220.65\n",
            "----------------------------------------------------------------\n",
            "Epoch 0: Best val loss inf, Best val acc 0.0000, best val recall 0.0000, best val precision 0.0000\n",
            "\t>>> Training: Loss 127.2286, Reg 0.000, Acc 0.2072, precision: 0.2072, recall0.2072\n",
            "\t>>> Val.    : Loss 1.8090, Reg 0.0000, Acc 0.6633, precision: 0.6633, recall0.6633\n",
            "Saved model with highest acc ...\n",
            "Epoch 1: Best val loss 1.8090, Best val acc 0.6633, best val recall 0.6633, best val precision 0.6633\n",
            "\t>>> Training: Loss 64.4818, Reg 0.000, Acc 0.4400, precision: 0.4400, recall0.4400\n",
            "\t>>> Val.    : Loss 1.7347, Reg 0.0000, Acc 0.6643, precision: 0.6643, recall0.6643\n",
            "Saved model with highest acc ...\n",
            "Epoch 2: Best val loss 1.7347, Best val acc 0.6643, best val recall 0.6643, best val precision 0.6643\n",
            "\t>>> Training: Loss 43.5213, Reg 0.000, Acc 0.5176, precision: 0.5176, recall0.5176\n",
            "\t>>> Val.    : Loss 1.6709, Reg 0.0000, Acc 0.6636, precision: 0.6636, recall0.6636\n",
            "Epoch 3: Best val loss 1.6709, Best val acc 0.6643, best val recall 0.6643, best val precision 0.6643\n",
            "\t>>> Training: Loss 33.0138, Reg 0.000, Acc 0.5564, precision: 0.5564, recall0.5564\n",
            "\t>>> Val.    : Loss 1.6133, Reg 0.0000, Acc 0.6653, precision: 0.6653, recall0.6653\n",
            "Saved model with highest acc ...\n",
            "Epoch 4: Best val loss 1.6133, Best val acc 0.6653, best val recall 0.6653, best val precision 0.6653\n",
            "\t>>> Training: Loss 26.6921, Reg 0.000, Acc 0.5797, precision: 0.5797, recall0.5797\n",
            "\t>>> Val.    : Loss 1.5639, Reg 0.0000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "Saved model with highest acc ...\n",
            "Epoch 5: Best val loss 1.5639, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 22.4665, Reg 0.000, Acc 0.5952, precision: 0.5952, recall0.5952\n",
            "\t>>> Val.    : Loss 1.5222, Reg 0.0000, Acc 0.6662, precision: 0.6662, recall0.6662\n",
            "Epoch 6: Best val loss 1.5222, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 19.4409, Reg 0.000, Acc 0.6063, precision: 0.6063, recall0.6063\n",
            "\t>>> Val.    : Loss 1.4863, Reg 0.0000, Acc 0.6660, precision: 0.6660, recall0.6660\n",
            "Epoch 7: Best val loss 1.4863, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 17.1669, Reg 0.000, Acc 0.6146, precision: 0.6146, recall0.6146\n",
            "\t>>> Val.    : Loss 1.4554, Reg 0.0000, Acc 0.6660, precision: 0.6660, recall0.6660\n",
            "Epoch 8: Best val loss 1.4554, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 15.3950, Reg 0.000, Acc 0.6211, precision: 0.6211, recall0.6211\n",
            "\t>>> Val.    : Loss 1.4287, Reg 0.0000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "Epoch 9: Best val loss 1.4287, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 13.9753, Reg 0.000, Acc 0.6263, precision: 0.6263, recall0.6263\n",
            "\t>>> Val.    : Loss 1.4052, Reg 0.0000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "Epoch 10: Best val loss 1.4052, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 12.8123, Reg 0.000, Acc 0.6305, precision: 0.6305, recall0.6305\n",
            "\t>>> Val.    : Loss 1.3849, Reg 0.0000, Acc 0.6660, precision: 0.6660, recall0.6660\n",
            "Epoch 11: Best val loss 1.3849, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 11.8421, Reg 0.000, Acc 0.6340, precision: 0.6340, recall0.6340\n",
            "\t>>> Val.    : Loss 1.3678, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 12: Best val loss 1.3678, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 11.0205, Reg 0.000, Acc 0.6370, precision: 0.6370, recall0.6370\n",
            "\t>>> Val.    : Loss 1.3525, Reg 0.0000, Acc 0.6656, precision: 0.6656, recall0.6656\n",
            "Epoch 13: Best val loss 1.3525, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 10.3158, Reg 0.000, Acc 0.6396, precision: 0.6396, recall0.6396\n",
            "\t>>> Val.    : Loss 1.3389, Reg 0.0000, Acc 0.6654, precision: 0.6654, recall0.6654\n",
            "Epoch 14: Best val loss 1.3389, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 9.7047, Reg 0.000, Acc 0.6418, precision: 0.6418, recall0.6418\n",
            "\t>>> Val.    : Loss 1.3269, Reg 0.0000, Acc 0.6654, precision: 0.6654, recall0.6654\n",
            "Epoch 15: Best val loss 1.3269, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 9.1698, Reg 0.000, Acc 0.6437, precision: 0.6437, recall0.6437\n",
            "\t>>> Val.    : Loss 1.3157, Reg 0.0000, Acc 0.6656, precision: 0.6656, recall0.6656\n",
            "Epoch 16: Best val loss 1.3157, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 8.6976, Reg 0.000, Acc 0.6454, precision: 0.6454, recall0.6454\n",
            "\t>>> Val.    : Loss 1.3065, Reg 0.0000, Acc 0.6654, precision: 0.6654, recall0.6654\n",
            "Epoch 17: Best val loss 1.3065, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 8.2777, Reg 0.000, Acc 0.6469, precision: 0.6469, recall0.6469\n",
            "\t>>> Val.    : Loss 1.2979, Reg 0.0000, Acc 0.6653, precision: 0.6653, recall0.6653\n",
            "Epoch 18: Best val loss 1.2979, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 7.9020, Reg 0.000, Acc 0.6483, precision: 0.6483, recall0.6483\n",
            "\t>>> Val.    : Loss 1.2896, Reg 0.0000, Acc 0.6655, precision: 0.6655, recall0.6655\n",
            "Epoch 19: Best val loss 1.2896, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 7.5637, Reg 0.000, Acc 0.6495, precision: 0.6495, recall0.6495\n",
            "\t>>> Val.    : Loss 1.2826, Reg 0.0000, Acc 0.6654, precision: 0.6654, recall0.6654\n",
            "Epoch 20: Best val loss 1.2826, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 7.2576, Reg 0.000, Acc 0.6506, precision: 0.6506, recall0.6506\n",
            "\t>>> Val.    : Loss 1.2759, Reg 0.0000, Acc 0.6655, precision: 0.6655, recall0.6655\n",
            "Epoch 21: Best val loss 1.2759, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 6.9793, Reg 0.000, Acc 0.6517, precision: 0.6517, recall0.6517\n",
            "\t>>> Val.    : Loss 1.2698, Reg 0.0000, Acc 0.6656, precision: 0.6656, recall0.6656\n",
            "Epoch 22: Best val loss 1.2698, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 6.7251, Reg 0.000, Acc 0.6526, precision: 0.6526, recall0.6526\n",
            "\t>>> Val.    : Loss 1.2641, Reg 0.0000, Acc 0.6656, precision: 0.6656, recall0.6656\n",
            "Epoch 23: Best val loss 1.2641, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 6.4921, Reg 0.000, Acc 0.6534, precision: 0.6534, recall0.6534\n",
            "\t>>> Val.    : Loss 1.2589, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 24: Best val loss 1.2589, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 6.2777, Reg 0.000, Acc 0.6542, precision: 0.6542, recall0.6542\n",
            "\t>>> Val.    : Loss 1.2544, Reg 0.0000, Acc 0.6656, precision: 0.6656, recall0.6656\n",
            "Epoch 25: Best val loss 1.2544, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 6.0797, Reg 0.000, Acc 0.6549, precision: 0.6549, recall0.6549\n",
            "\t>>> Val.    : Loss 1.2502, Reg 0.0000, Acc 0.6656, precision: 0.6656, recall0.6656\n",
            "Epoch 26: Best val loss 1.2502, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 5.8964, Reg 0.000, Acc 0.6556, precision: 0.6556, recall0.6556\n",
            "\t>>> Val.    : Loss 1.2463, Reg 0.0000, Acc 0.6655, precision: 0.6655, recall0.6655\n",
            "Epoch 27: Best val loss 1.2463, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 5.7262, Reg 0.000, Acc 0.6562, precision: 0.6562, recall0.6562\n",
            "\t>>> Val.    : Loss 1.2426, Reg 0.0000, Acc 0.6655, precision: 0.6655, recall0.6655\n",
            "Epoch 28: Best val loss 1.2426, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 5.5677, Reg 0.000, Acc 0.6568, precision: 0.6568, recall0.6568\n",
            "\t>>> Val.    : Loss 1.2391, Reg 0.0000, Acc 0.6655, precision: 0.6655, recall0.6655\n",
            "Epoch 29: Best val loss 1.2391, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 5.4198, Reg 0.000, Acc 0.6573, precision: 0.6573, recall0.6573\n",
            "\t>>> Val.    : Loss 1.2356, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 30: Best val loss 1.2356, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 5.2814, Reg 0.000, Acc 0.6578, precision: 0.6578, recall0.6578\n",
            "\t>>> Val.    : Loss 1.2323, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 31: Best val loss 1.2323, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 5.1516, Reg 0.000, Acc 0.6583, precision: 0.6583, recall0.6583\n",
            "\t>>> Val.    : Loss 1.2295, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 32: Best val loss 1.2295, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 5.0297, Reg 0.000, Acc 0.6587, precision: 0.6587, recall0.6587\n",
            "\t>>> Val.    : Loss 1.2268, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 33: Best val loss 1.2268, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.9149, Reg 0.000, Acc 0.6591, precision: 0.6591, recall0.6591\n",
            "\t>>> Val.    : Loss 1.2240, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 34: Best val loss 1.2240, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.8067, Reg 0.000, Acc 0.6595, precision: 0.6595, recall0.6595\n",
            "\t>>> Val.    : Loss 1.2215, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 35: Best val loss 1.2215, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.7045, Reg 0.000, Acc 0.6599, precision: 0.6599, recall0.6599\n",
            "\t>>> Val.    : Loss 1.2192, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 36: Best val loss 1.2192, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.6079, Reg 0.000, Acc 0.6602, precision: 0.6602, recall0.6602\n",
            "\t>>> Val.    : Loss 1.2172, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 37: Best val loss 1.2172, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.5163, Reg 0.000, Acc 0.6606, precision: 0.6606, recall0.6606\n",
            "\t>>> Val.    : Loss 1.2148, Reg 0.0000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "Epoch 38: Best val loss 1.2148, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.4294, Reg 0.000, Acc 0.6609, precision: 0.6609, recall0.6609\n",
            "\t>>> Val.    : Loss 1.2128, Reg 0.0000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "Epoch 39: Best val loss 1.2128, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.3468, Reg 0.000, Acc 0.6612, precision: 0.6612, recall0.6612\n",
            "\t>>> Val.    : Loss 1.2110, Reg 0.0000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "Epoch 40: Best val loss 1.2110, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.2683, Reg 0.000, Acc 0.6615, precision: 0.6615, recall0.6615\n",
            "\t>>> Val.    : Loss 1.2091, Reg 0.0000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "Epoch 41: Best val loss 1.2091, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.1935, Reg 0.000, Acc 0.6617, precision: 0.6617, recall0.6617\n",
            "\t>>> Val.    : Loss 1.2076, Reg 0.0000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "Epoch 42: Best val loss 1.2076, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.1221, Reg 0.000, Acc 0.6620, precision: 0.6620, recall0.6620\n",
            "\t>>> Val.    : Loss 1.2060, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 43: Best val loss 1.2060, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 4.0541, Reg 0.000, Acc 0.6622, precision: 0.6622, recall0.6622\n",
            "\t>>> Val.    : Loss 1.2046, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 44: Best val loss 1.2046, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.9890, Reg 0.000, Acc 0.6625, precision: 0.6625, recall0.6625\n",
            "\t>>> Val.    : Loss 1.2032, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 45: Best val loss 1.2032, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.9268, Reg 0.000, Acc 0.6627, precision: 0.6627, recall0.6627\n",
            "\t>>> Val.    : Loss 1.2016, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 46: Best val loss 1.2016, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.8672, Reg 0.000, Acc 0.6629, precision: 0.6629, recall0.6629\n",
            "\t>>> Val.    : Loss 1.2002, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 47: Best val loss 1.2002, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.8101, Reg 0.000, Acc 0.6631, precision: 0.6631, recall0.6631\n",
            "\t>>> Val.    : Loss 1.1991, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 48: Best val loss 1.1991, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.7553, Reg 0.000, Acc 0.6633, precision: 0.6633, recall0.6633\n",
            "\t>>> Val.    : Loss 1.1977, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 49: Best val loss 1.1977, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.7027, Reg 0.000, Acc 0.6635, precision: 0.6635, recall0.6635\n",
            "\t>>> Val.    : Loss 1.1965, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 50: Best val loss 1.1965, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.6522, Reg 0.000, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "\t>>> Val.    : Loss 1.1955, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 51: Best val loss 1.1955, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.6036, Reg 0.000, Acc 0.6639, precision: 0.6639, recall0.6639\n",
            "\t>>> Val.    : Loss 1.1944, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 52: Best val loss 1.1944, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.5569, Reg 0.000, Acc 0.6640, precision: 0.6640, recall0.6640\n",
            "\t>>> Val.    : Loss 1.1935, Reg 0.0000, Acc 0.6656, precision: 0.6656, recall0.6656\n",
            "Epoch 53: Best val loss 1.1935, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.5119, Reg 0.000, Acc 0.6642, precision: 0.6642, recall0.6642\n",
            "\t>>> Val.    : Loss 1.1925, Reg 0.0000, Acc 0.6656, precision: 0.6656, recall0.6656\n",
            "Epoch 54: Best val loss 1.1925, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.4685, Reg 0.000, Acc 0.6644, precision: 0.6644, recall0.6644\n",
            "\t>>> Val.    : Loss 1.1914, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 55: Best val loss 1.1914, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.4266, Reg 0.000, Acc 0.6645, precision: 0.6645, recall0.6645\n",
            "\t>>> Val.    : Loss 1.1905, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 56: Best val loss 1.1905, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.3863, Reg 0.000, Acc 0.6646, precision: 0.6646, recall0.6646\n",
            "\t>>> Val.    : Loss 1.1896, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 57: Best val loss 1.1896, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.3473, Reg 0.000, Acc 0.6648, precision: 0.6648, recall0.6648\n",
            "\t>>> Val.    : Loss 1.1886, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 58: Best val loss 1.1886, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.3096, Reg 0.000, Acc 0.6649, precision: 0.6649, recall0.6649\n",
            "\t>>> Val.    : Loss 1.1876, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 59: Best val loss 1.1876, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.2732, Reg 0.000, Acc 0.6651, precision: 0.6651, recall0.6651\n",
            "\t>>> Val.    : Loss 1.1868, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 60: Best val loss 1.1868, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.2380, Reg 0.000, Acc 0.6652, precision: 0.6652, recall0.6652\n",
            "\t>>> Val.    : Loss 1.1860, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 61: Best val loss 1.1860, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.2040, Reg 0.000, Acc 0.6653, precision: 0.6653, recall0.6653\n",
            "\t>>> Val.    : Loss 1.1852, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 62: Best val loss 1.1852, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.1710, Reg 0.000, Acc 0.6654, precision: 0.6654, recall0.6654\n",
            "\t>>> Val.    : Loss 1.1844, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 63: Best val loss 1.1844, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.1390, Reg 0.000, Acc 0.6655, precision: 0.6655, recall0.6655\n",
            "\t>>> Val.    : Loss 1.1836, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 64: Best val loss 1.1836, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.1080, Reg 0.000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "\t>>> Val.    : Loss 1.1829, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 65: Best val loss 1.1829, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.0780, Reg 0.000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "\t>>> Val.    : Loss 1.1821, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 66: Best val loss 1.1821, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.0489, Reg 0.000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "\t>>> Val.    : Loss 1.1813, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 67: Best val loss 1.1813, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 3.0206, Reg 0.000, Acc 0.6660, precision: 0.6660, recall0.6660\n",
            "\t>>> Val.    : Loss 1.1806, Reg 0.0000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "Epoch 68: Best val loss 1.1806, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.9931, Reg 0.000, Acc 0.6661, precision: 0.6661, recall0.6661\n",
            "\t>>> Val.    : Loss 1.1800, Reg 0.0000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "Epoch 69: Best val loss 1.1800, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.9664, Reg 0.000, Acc 0.6662, precision: 0.6662, recall0.6662\n",
            "\t>>> Val.    : Loss 1.1795, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 70: Best val loss 1.1795, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.9405, Reg 0.000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "\t>>> Val.    : Loss 1.1790, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 71: Best val loss 1.1790, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.9153, Reg 0.000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "\t>>> Val.    : Loss 1.1785, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 72: Best val loss 1.1785, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.8908, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.1780, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 73: Best val loss 1.1780, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.8669, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.1774, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 74: Best val loss 1.1774, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.8437, Reg 0.000, Acc 0.6666, precision: 0.6666, recall0.6666\n",
            "\t>>> Val.    : Loss 1.1770, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 75: Best val loss 1.1770, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.8211, Reg 0.000, Acc 0.6667, precision: 0.6667, recall0.6667\n",
            "\t>>> Val.    : Loss 1.1764, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 76: Best val loss 1.1764, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.7991, Reg 0.000, Acc 0.6668, precision: 0.6668, recall0.6668\n",
            "\t>>> Val.    : Loss 1.1759, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 77: Best val loss 1.1759, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.7776, Reg 0.000, Acc 0.6668, precision: 0.6668, recall0.6668\n",
            "\t>>> Val.    : Loss 1.1753, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 78: Best val loss 1.1753, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.7567, Reg 0.000, Acc 0.6669, precision: 0.6669, recall0.6669\n",
            "\t>>> Val.    : Loss 1.1749, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 79: Best val loss 1.1749, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.7363, Reg 0.000, Acc 0.6670, precision: 0.6670, recall0.6670\n",
            "\t>>> Val.    : Loss 1.1744, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 80: Best val loss 1.1744, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.7164, Reg 0.000, Acc 0.6671, precision: 0.6671, recall0.6671\n",
            "\t>>> Val.    : Loss 1.1740, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 81: Best val loss 1.1740, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.6970, Reg 0.000, Acc 0.6671, precision: 0.6671, recall0.6671\n",
            "\t>>> Val.    : Loss 1.1735, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 82: Best val loss 1.1735, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.6781, Reg 0.000, Acc 0.6672, precision: 0.6672, recall0.6672\n",
            "\t>>> Val.    : Loss 1.1731, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 83: Best val loss 1.1731, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.6596, Reg 0.000, Acc 0.6673, precision: 0.6673, recall0.6673\n",
            "\t>>> Val.    : Loss 1.1727, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 84: Best val loss 1.1727, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.6415, Reg 0.000, Acc 0.6673, precision: 0.6673, recall0.6673\n",
            "\t>>> Val.    : Loss 1.1722, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 85: Best val loss 1.1722, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.6239, Reg 0.000, Acc 0.6674, precision: 0.6674, recall0.6674\n",
            "\t>>> Val.    : Loss 1.1718, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 86: Best val loss 1.1718, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.6067, Reg 0.000, Acc 0.6675, precision: 0.6675, recall0.6675\n",
            "\t>>> Val.    : Loss 1.1715, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 87: Best val loss 1.1715, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.5899, Reg 0.000, Acc 0.6675, precision: 0.6675, recall0.6675\n",
            "\t>>> Val.    : Loss 1.1712, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 88: Best val loss 1.1712, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.5734, Reg 0.000, Acc 0.6676, precision: 0.6676, recall0.6676\n",
            "\t>>> Val.    : Loss 1.1708, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 89: Best val loss 1.1708, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.5573, Reg 0.000, Acc 0.6676, precision: 0.6676, recall0.6676\n",
            "\t>>> Val.    : Loss 1.1705, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 90: Best val loss 1.1705, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.5416, Reg 0.000, Acc 0.6677, precision: 0.6677, recall0.6677\n",
            "\t>>> Val.    : Loss 1.1702, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 91: Best val loss 1.1702, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.5262, Reg 0.000, Acc 0.6678, precision: 0.6678, recall0.6678\n",
            "\t>>> Val.    : Loss 1.1698, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 92: Best val loss 1.1698, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.5111, Reg 0.000, Acc 0.6678, precision: 0.6678, recall0.6678\n",
            "\t>>> Val.    : Loss 1.1695, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 93: Best val loss 1.1695, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.4964, Reg 0.000, Acc 0.6679, precision: 0.6679, recall0.6679\n",
            "\t>>> Val.    : Loss 1.1691, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 94: Best val loss 1.1691, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.4819, Reg 0.000, Acc 0.6679, precision: 0.6679, recall0.6679\n",
            "\t>>> Val.    : Loss 1.1688, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 95: Best val loss 1.1688, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.4678, Reg 0.000, Acc 0.6680, precision: 0.6680, recall0.6680\n",
            "\t>>> Val.    : Loss 1.1684, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 96: Best val loss 1.1684, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.4540, Reg 0.000, Acc 0.6680, precision: 0.6680, recall0.6680\n",
            "\t>>> Val.    : Loss 1.1681, Reg 0.0000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "Epoch 97: Best val loss 1.1681, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.4404, Reg 0.000, Acc 0.6681, precision: 0.6681, recall0.6681\n",
            "\t>>> Val.    : Loss 1.1677, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 98: Best val loss 1.1677, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.4271, Reg 0.000, Acc 0.6681, precision: 0.6681, recall0.6681\n",
            "\t>>> Val.    : Loss 1.1674, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "Epoch 99: Best val loss 1.1674, Best val acc 0.6663, best val recall 0.6663, best val precision 0.6663\n",
            "\t>>> Training: Loss 2.4141, Reg 0.000, Acc 0.6682, precision: 0.6682, recall0.6682\n",
            "\t>>> Val.    : Loss 1.1671, Reg 0.0000, Acc 0.6658, precision: 0.6658, recall0.6658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%mkdir /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints"
      ],
      "metadata": {
        "id": "O4m8fvzN-oJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4"
      ],
      "metadata": {
        "id": "UULfzcFrynFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%cp ./saved/model/epoch97_acc_0.762.ckpt /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints/CIRCLE/mobilenetv3l/"
      ],
      "metadata": {
        "id": "1hFw2rQB-7np"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}