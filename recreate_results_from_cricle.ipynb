{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_HSnGPDTmtQqL19RJaSZ9opYOjST_pFh",
      "authorship_tag": "ABX9TyMiiwCOjQkuKFPjos65xOzc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamCorbinFAUPhD/CIRCLe-experiments/blob/main/recreate_results_from_cricle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "This notebook is used to re-create the results from this paper : [CIRCLe: Color Invariant Representation\n",
        "Learning for Unbiased Classification of Skin\n",
        "Lesions](https://arxiv.org/pdf/2208.13528.pdf)\n",
        "\n",
        "Their github repo is : https://github.com/arezou-pakzad/CIRCLe\n",
        "\n",
        "This paper uses the Fitzpatrick17k dataset which can be obtained here: https://github.com/mattgroh/fitzpatrick17k"
      ],
      "metadata": {
        "id": "jCpy2CqVJ-VI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the environment"
      ],
      "metadata": {
        "id": "1IqTnocWPMkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import torch"
      ],
      "metadata": {
        "id": "ylyPAeA2lHbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeftXarNVjWU",
        "outputId": "10a4e293-2fcd-425d-d432-e4ff33dc8b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [1\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [W\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,188 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,551 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,020 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,452 kB]\n",
            "Get:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,164 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,230 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,329 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,109 kB]\n",
            "Get:22 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:23 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [50.8 kB]\n",
            "Fetched 16.5 MB in 5s (3,360 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8 python3.8-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 4,693 kB of archives.\n",
            "After this operation, 18.5 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-minimal amd64 3.8.15-1+bionic1 [762 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.8-minimal amd64 3.8.15-1+bionic1 [1,838 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-stdlib amd64 3.8.15-1+bionic1 [1,658 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.8 amd64 3.8.15-1+bionic1 [435 kB]\n",
            "Fetched 4,693 kB in 4s (1,117 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 123934 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.8-minimal_3.8.15-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.15-1+bionic1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../python3.8-minimal_3.8.15-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.15-1+bionic1) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.8-stdlib_3.8.15-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.15-1+bionic1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../python3.8_3.8.15-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.15-1+bionic1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.15-1+bionic1) ...\n",
            "Setting up python3.8-minimal (3.8.15-1+bionic1) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.15-1+bionic1) ...\n",
            "Setting up python3.8 (3.8.15-1+bionic1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1"
      ],
      "metadata": {
        "id": "3gpxKl1AWZ5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select python version"
      ],
      "metadata": {
        "id": "e2EdekHBcbjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next block we have to manually select python 3.8 by pressing 3 after the next block of code runs and waits for user input"
      ],
      "metadata": {
        "id": "0-z3InNGWz0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --config python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6-tlk1kWsmJ",
        "outputId": "461a2e96-6e0d-4682-9442-782d104f55c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.7   2         auto mode\n",
            "  1            /usr/bin/python3.6   1         manual mode\n",
            "  2            /usr/bin/python3.7   2         manual mode\n",
            "  3            /usr/bin/python3.8   1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 3\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in manual mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python3.8-distutils && wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxLRkbETXkE4",
        "outputId": "5043505f-37f1-498b-ebbf-467e43ef707a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.8-distutils'\n",
            "python3-distutils is already the newest version (3.6.9-1~18.04).\n",
            "python3-distutils set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "--2022-10-14 17:01:52--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2560808 (2.4M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.44M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-10-14 17:01:52 (57.3 MB/s) - ‘get-pip.py’ saved [2560808/2560808]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pip\n",
            "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools\n",
            "  Downloading setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel\n",
            "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-22.2.2 setuptools-65.5.0 wheel-0.37.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX3pAmwlWnf5",
        "outputId": "b25b0433-e5f9-456d-b13c-cbb73c060843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download latest code"
      ],
      "metadata": {
        "id": "cLWa0BAdPQBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kQ5LposJzeZ",
        "outputId": "506b3722-1094-4c6a-c818-85cd6fb8576c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CIRCLe'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 92 (delta 45), reused 66 (delta 26), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (92/92), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/acorbin3/CIRCLe.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./CIRCLe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9eGp7LOm90J",
        "outputId": "410fb575-4be3-4759-b69d-6780b80a0131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CIRCLe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNNuLRyKQ7-",
        "outputId": "05b365ce-b39c-4c28-b9aa-e1962dd8acc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r ./requirements.txt"
      ],
      "metadata": {
        "id": "DWzYtBAIKvuD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4606bec-ab4a-4b55-be13-cb029b27a1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23.2\n",
            "  Downloading numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.4.4\n",
            "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.2.0\n",
            "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==1.1.2\n",
            "  Downloading scikit_learn-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.9.2\n",
            "  Downloading tensorflow-2.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.12.1\n",
            "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.1\n",
            "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2022.4-py2.py3-none-any.whl (500 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.8/500.8 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.3.2\n",
            "  Downloading scipy-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=1.0.0\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.49.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py>=2.9.0\n",
            "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (65.5.0)\n",
            "Collecting typing-extensions>=3.6.6\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>=1.12.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting libclang>=13.0.0\n",
            "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.37.1)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.8/169.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing!=3.0.5,>=2.0.2\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.9.0-py3-none-any.whl (5.8 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pytz, pyasn1, libclang, keras, flatbuffers, zipp, wrapt, urllib3, typing-extensions, tqdm, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, rsa, pyparsing, pyasn1-modules, protobuf, Pillow, oauthlib, numpy, MarkupSafe, joblib, idna, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, torch, scipy, requests, python-dateutil, packaging, opt-einsum, keras-preprocessing, importlib-metadata, h5py, grpcio, google-pasta, google-auth, astunparse, torchvision, scikit_learn, requests-oauthlib, pandas, markdown, google-auth-oauthlib, tensorboard, tensorflow\n",
            "Successfully installed MarkupSafe-2.1.1 Pillow-9.2.0 absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 certifi-2022.9.24 charset-normalizer-2.1.1 flatbuffers-1.12 gast-0.4.0 google-auth-2.12.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.49.1 h5py-3.7.0 idna-3.4 importlib-metadata-5.0.0 joblib-1.2.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 numpy-1.23.2 oauthlib-3.2.1 opt-einsum-3.3.0 packaging-21.3 pandas-1.4.4 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2022.4 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 scikit_learn-1.1.2 scipy-1.9.2 six-1.16.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.2 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 threadpoolctl-3.1.0 torch-1.12.1 torchvision-0.13.1 tqdm-4.64.1 typing-extensions-4.4.0 urllib3-1.26.12 werkzeug-2.2.2 wrapt-1.14.1 zipp-3.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "astunparse",
                  "certifi",
                  "dateutil",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy over Fitzpatrick files from Google Drive to local directory"
      ],
      "metadata": {
        "id": "A_tmSZWHPYFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to connect google drive in the files section over on the left hand side of Google Colab\n",
        "!ls -l\n",
        "%cp /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/fitzpatrick17k.zip /content/CIRCLe/"
      ],
      "metadata": {
        "id": "xiQTQfZdMf9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d6fcd40-de29-4b31-9402-6fbcd5dd2861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 7892\n",
            "-rwxr-xr-x 1 root root    5142 Oct 14 17:01 dataset.py\n",
            "-rw-r--r-- 1 root root  385383 Oct 14 17:01 fitz17k_test_random_holdout.csv\n",
            "-rw-r--r-- 1 root root 3089679 Oct 14 17:01 fitz17k_train_random_holdout.csv\n",
            "-rw-r--r-- 1 root root  389648 Oct 14 17:01 fitz17k_val_random_holdout.csv\n",
            "-rw-r--r-- 1 root root 4104341 Oct 14 17:01 fitzpatrick17k.csv\n",
            "drwxr-xr-x 2 root root    4096 Oct 14 17:01 images\n",
            "-rw-r--r-- 1 root root   34523 Oct 14 17:01 LICENSE\n",
            "-rwxr-xr-x 1 root root     419 Oct 14 17:01 logger.py\n",
            "-rwxr-xr-x 1 root root    4524 Oct 14 17:01 main.py\n",
            "drwxr-xr-x 2 root root    4096 Oct 14 17:01 models\n",
            "-rw-r--r-- 1 root root    3245 Oct 14 17:01 README.md\n",
            "-rw-r--r-- 1 root root     127 Oct 14 17:01 requirements.txt\n",
            "-rwxr-xr-x 1 root root   12090 Oct 14 17:01 solver_stargan.py\n",
            "-rw-r--r-- 1 root root    1055 Oct 14 17:01 splitting_the_data.py\n",
            "-rwxr-xr-x 1 root root    3830 Oct 14 17:01 train_stargan.py\n",
            "-rwxr-xr-x 1 root root     356 Oct 14 17:01 util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpack fitzpatrick 17k dataset\n",
        "file_name_with_path = \"/content/CIRCLe/fitzpatrick17k.zip\"\n",
        "with zipfile.ZipFile(file_name_with_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/CIRCLe\")"
      ],
      "metadata": {
        "id": "QLLSthA0bBRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_files = \"/content/CIRCLe/data/finalfitz17k/\""
      ],
      "metadata": {
        "id": "7U6nLM-0cDfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy over csv files to where the images are located\n",
        "!cp ./*.csv $path_to_files"
      ],
      "metadata": {
        "id": "i22P_ORwH8Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tranining StarGAN"
      ],
      "metadata": {
        "id": "nt6Hj8htmxVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folder for where the STAR Gan files will be saved\n",
        "%mkdir ./gan-path"
      ],
      "metadata": {
        "id": "4MDtn5nJllma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python train_stargan.py --model_save_dir ./gan-path --data_dir $path_to_files"
      ],
      "metadata": {
        "id": "bAC3Y3BhcE1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy StarGAN models over to Google Drive"
      ],
      "metadata": {
        "id": "S7OR7rSsM-Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%cp ./gan-path/*.ckpt /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/"
      ],
      "metadata": {
        "id": "KVsWpgMjnJJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the StarGAN models back over to local\n",
        "%cp /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/*.ckpt /content/CIRCLe/gan-path"
      ],
      "metadata": {
        "id": "eH6ort8mkWYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train CIRCLe model "
      ],
      "metadata": {
        "id": "fKUV22LhVzBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir ./saved\n",
        "%mkdir ./saved/model"
      ],
      "metadata": {
        "id": "08ngcZp9m1-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --gan_path ./gan-path/ --use_reg_loss True --data_dir $path_to_files --base mobilenetv3l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH5FKsbclkje",
        "outputId": "450d1d9b-2053-43ba-c834-1fe58a442268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flags:\n",
            "\talpha: 0.1\n",
            "\tbase: mobilenetv3l\n",
            "\tbatch_size: 32\n",
            "\tdata_dir: /content/CIRCLe/data/finalfitz17k/\n",
            "\tdataset: FitzPatrick17k\n",
            "\tepochs: 100\n",
            "\tgan_path: ./gan-path/\n",
            "\thidden_dim: 256\n",
            "\tlr: 0.001\n",
            "\tmodel: circle\n",
            "\tmodel_save_dir: saved/model/\n",
            "\tnum_classes: 114\n",
            "\tseed: 1\n",
            "\tuse_reg_loss: True\n",
            "\tweight_decay: 0.001\n",
            "\ttrain: skin type 1 : 2358\n",
            "\ttrain: skin type 2 : 3842\n",
            "\ttrain: skin type 3 : 2658\n",
            "\ttrain: skin type 4 : 2220\n",
            "\ttrain: skin type 5 : 1217\n",
            "\ttrain: skin type 6 : 515\n",
            "train size: 12810\n",
            "val size: 1603\n",
            "train skin types: [4 6 2 3 1 5]\n",
            "val skin types: [3 2 4 5 1 6]\n",
            "train skin conditions: 114\n",
            "val skin conditions: 114\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
            "100% 21.1M/21.1M [00:00<00:00, 85.3MB/s]\n",
            "Epoch 0: Best val loss inf, Best val acc 0.0\n",
            ">>> Training: Loss  4.568 , Reg  0.016 , Acc  0.044\n",
            ">>> Val: Loss  4.444 , Reg  0.000 , Acc  0.051\n",
            "Saved model with highest acc ...\n",
            "Epoch 1: Best val loss inf, Best val acc 0.050625\n",
            ">>> Training: Loss  4.265 , Reg  0.024 , Acc  0.087\n",
            ">>> Val: Loss  4.226 , Reg  0.000 , Acc  0.096\n",
            "Saved model with highest acc ...\n",
            "Epoch 2: Best val loss inf, Best val acc 0.095625\n",
            ">>> Training: Loss  3.944 , Reg  0.038 , Acc  0.134\n",
            ">>> Val: Loss  3.951 , Reg  0.000 , Acc  0.152\n",
            "Saved model with highest acc ...\n",
            "Epoch 3: Best val loss inf, Best val acc 0.151875\n",
            ">>> Training: Loss  3.567 , Reg  0.058 , Acc  0.195\n",
            ">>> Val: Loss  3.657 , Reg  0.000 , Acc  0.196\n",
            "Saved model with highest acc ...\n",
            "Epoch 4: Best val loss inf, Best val acc 0.195625\n",
            ">>> Training: Loss  3.222 , Reg  0.079 , Acc  0.252\n",
            ">>> Val: Loss  3.483 , Reg  0.000 , Acc  0.211\n",
            "Saved model with highest acc ...\n",
            "Epoch 5: Best val loss inf, Best val acc 0.210625\n",
            ">>> Training: Loss  2.926 , Reg  0.096 , Acc  0.309\n",
            ">>> Val: Loss  3.344 , Reg  0.000 , Acc  0.234\n",
            "Saved model with highest acc ...\n",
            "Epoch 6: Best val loss inf, Best val acc 0.23375\n",
            ">>> Training: Loss  2.660 , Reg  0.108 , Acc  0.361\n",
            ">>> Val: Loss  3.216 , Reg  0.000 , Acc  0.258\n",
            "Saved model with highest acc ...\n",
            "Epoch 7: Best val loss inf, Best val acc 0.258125\n",
            ">>> Training: Loss  2.417 , Reg  0.118 , Acc  0.413\n",
            ">>> Val: Loss  3.186 , Reg  0.000 , Acc  0.269\n",
            "Saved model with highest acc ...\n",
            "Epoch 8: Best val loss inf, Best val acc 0.269375\n",
            ">>> Training: Loss  2.192 , Reg  0.126 , Acc  0.466\n",
            ">>> Val: Loss  3.112 , Reg  0.000 , Acc  0.286\n",
            "Saved model with highest acc ...\n",
            "Epoch 9: Best val loss inf, Best val acc 0.285625\n",
            ">>> Training: Loss  1.986 , Reg  0.133 , Acc  0.517\n",
            ">>> Val: Loss  3.074 , Reg  0.000 , Acc  0.299\n",
            "Saved model with highest acc ...\n",
            "Epoch 10: Best val loss inf, Best val acc 0.299375\n",
            ">>> Training: Loss  1.793 , Reg  0.140 , Acc  0.564\n",
            ">>> Val: Loss  3.052 , Reg  0.000 , Acc  0.311\n",
            "Saved model with highest acc ...\n",
            "Epoch 11: Best val loss inf, Best val acc 0.31125\n",
            ">>> Training: Loss  1.608 , Reg  0.145 , Acc  0.604\n",
            ">>> Val: Loss  3.090 , Reg  0.000 , Acc  0.307\n",
            "Epoch 12: Best val loss inf, Best val acc 0.31125\n",
            ">>> Training: Loss  1.421 , Reg  0.152 , Acc  0.651\n",
            ">>> Val: Loss  3.104 , Reg  0.000 , Acc  0.321\n",
            "Saved model with highest acc ...\n",
            "Epoch 13: Best val loss inf, Best val acc 0.320625\n",
            ">>> Training: Loss  1.249 , Reg  0.158 , Acc  0.694\n",
            ">>> Val: Loss  3.158 , Reg  0.000 , Acc  0.316\n",
            "Epoch 14: Best val loss inf, Best val acc 0.320625\n",
            ">>> Training: Loss  1.090 , Reg  0.163 , Acc  0.738\n",
            ">>> Val: Loss  3.153 , Reg  0.000 , Acc  0.326\n",
            "Saved model with highest acc ...\n",
            "Epoch 15: Best val loss inf, Best val acc 0.325625\n",
            ">>> Training: Loss  0.939 , Reg  0.168 , Acc  0.778\n",
            ">>> Val: Loss  3.194 , Reg  0.000 , Acc  0.332\n",
            "Saved model with highest acc ...\n",
            "Epoch 16: Best val loss inf, Best val acc 0.331875\n",
            ">>> Training: Loss  0.798 , Reg  0.172 , Acc  0.820\n",
            ">>> Val: Loss  3.229 , Reg  0.000 , Acc  0.332\n",
            "Epoch 17: Best val loss inf, Best val acc 0.331875\n",
            ">>> Training: Loss  0.674 , Reg  0.175 , Acc  0.852\n",
            ">>> Val: Loss  3.257 , Reg  0.000 , Acc  0.338\n",
            "Saved model with highest acc ...\n",
            "Epoch 18: Best val loss inf, Best val acc 0.3375\n",
            ">>> Training: Loss  0.575 , Reg  0.178 , Acc  0.880\n",
            ">>> Val: Loss  3.330 , Reg  0.000 , Acc  0.332\n",
            "Epoch 19: Best val loss inf, Best val acc 0.3375\n",
            ">>> Training: Loss  0.480 , Reg  0.179 , Acc  0.909\n",
            ">>> Val: Loss  3.371 , Reg  0.000 , Acc  0.331\n",
            "Epoch 20: Best val loss inf, Best val acc 0.3375\n",
            ">>> Training: Loss  0.409 , Reg  0.179 , Acc  0.927\n",
            ">>> Val: Loss  3.371 , Reg  0.000 , Acc  0.334\n",
            "Epoch 21: Best val loss inf, Best val acc 0.3375\n",
            ">>> Training: Loss  0.343 , Reg  0.179 , Acc  0.948\n",
            ">>> Val: Loss  3.391 , Reg  0.000 , Acc  0.339\n",
            "Saved model with highest acc ...\n",
            "Epoch 22: Best val loss inf, Best val acc 0.33875\n",
            ">>> Training: Loss  0.293 , Reg  0.177 , Acc  0.958\n",
            ">>> Val: Loss  3.423 , Reg  0.000 , Acc  0.335\n",
            "Epoch 23: Best val loss inf, Best val acc 0.33875\n",
            ">>> Training: Loss  0.250 , Reg  0.174 , Acc  0.970\n",
            ">>> Val: Loss  3.422 , Reg  0.000 , Acc  0.339\n",
            "Epoch 24: Best val loss inf, Best val acc 0.33875\n",
            ">>> Training: Loss  0.221 , Reg  0.171 , Acc  0.976\n",
            ">>> Val: Loss  3.429 , Reg  0.000 , Acc  0.343\n",
            "Saved model with highest acc ...\n",
            "Epoch 25: Best val loss inf, Best val acc 0.343125\n",
            ">>> Training: Loss  0.196 , Reg  0.167 , Acc  0.980\n",
            ">>> Val: Loss  3.422 , Reg  0.000 , Acc  0.354\n",
            "Saved model with highest acc ...\n",
            "Epoch 26: Best val loss inf, Best val acc 0.35375\n",
            ">>> Training: Loss  0.169 , Reg  0.164 , Acc  0.988\n",
            ">>> Val: Loss  3.443 , Reg  0.000 , Acc  0.352\n",
            "Epoch 27: Best val loss inf, Best val acc 0.35375\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 82, in <module>\n",
            "    for data in tqdm(train_loader, ncols=75, leave=False):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tqdm/std.py\", line 1195, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 681, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 721, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/CIRCLe/dataset.py\", line 38, in __getitem__\n",
            "    image = self.transform(image)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\", line 94, in __call__\n",
            "    img = t(img)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\", line 1355, in forward\n",
            "    return F.rotate(img, angle, self.resample, self.expand, self.center, fill)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\", line 1070, in rotate\n",
            "    return F_pil.rotate(img, angle=angle, interpolation=pil_interpolation, expand=expand, center=center, fill=fill)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_pil.py\", line 344, in rotate\n",
            "    return img.rotate(angle, interpolation, expand, center, **opts)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2232, in rotate\n",
            "    return self.transform(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2589, in transform\n",
            "    im.__transformer(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2665, in __transformer\n",
            "    image.load()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 257, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.device_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LF2V41CWwLp",
        "outputId": "4d3390e0-1d10-4849-e31f-4e8e6a377cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints"
      ],
      "metadata": {
        "id": "O4m8fvzN-oJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cp ./saved/model/*.ckpt /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints"
      ],
      "metadata": {
        "id": "28wMJfeDZsfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1hFw2rQB-7np"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}