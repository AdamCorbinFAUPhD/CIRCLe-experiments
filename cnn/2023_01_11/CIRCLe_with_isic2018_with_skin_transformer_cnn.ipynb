{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_HSnGPDTmtQqL19RJaSZ9opYOjST_pFh",
      "authorship_tag": "ABX9TyN3xEkRObdwb3aDQZn1Kce4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamCorbinFAUPhD/CIRCLe-experiments/blob/main/cnn/2023_01_11/CIRCLe_with_isic2018_with_skin_transformer_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment notes\n",
        "\n",
        "- date: 2023/01/11 8:26am\n",
        "- base model: simple cnn \n",
        "- Trying to add and test simple CNN\n",
        "\n",
        "Results: \n",
        "- overfitting \n"
      ],
      "metadata": {
        "id": "5K9KcPXtTmUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "This notebook is used to modify the implementation of CIRCLe from this paper : [CIRCLe: Color Invariant Representation\n",
        "Learning for Unbiased Classification of Skin\n",
        "Lesions](https://arxiv.org/pdf/2208.13528.pdf)\n",
        "\n",
        "Their github repo is : https://github.com/arezou-pakzad/CIRCLe\n",
        "\n",
        "This paper uses the Fitzpatrick17k dataset which can be obtained here: https://github.com/mattgroh/fitzpatrick17k\n",
        "\n",
        "For these set of experiments we will use the ISIC 2017 dataset from: https://github.com/manideep2510/melanoma_segmentation.git "
      ],
      "metadata": {
        "id": "jCpy2CqVJ-VI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO list\n",
        "\n",
        "1. [X] Download 2018 dataset\n",
        "1. [X] Analize dataset to get Fitzpatrick info. \n",
        "1. [X] Save off Fitzpatrick info data so we dont have to do it every time\n",
        "1. [X] load cached fitzpatrick data\n",
        "1. [X] Create masks uing https://github.com/DebeshJha/2020-CBMS-DoubleU-Net Because Task 3 for 2018 doesnt havent masks. Trick was to get the higher end GPU and ram (12/29/2022)\n",
        "1. [X] Create pytorch dataloader for ISIC 2018 dataset including loading masks, images, diagnossis, fitzpatrick type for training (12/30/2022) needed to create custom split function\n",
        "1. [X] Create dataloaders for test and validation  (12/30/2022)\n",
        "1. [X] Added jupiter notebook download code into the github repo (1/1/2023)\n",
        "1. [X] plug in dataloader into CIRCLe main file (1/1/2023)\n",
        "1. [X] Figure out how to transform image and mask the same from the dataloader (1/2/2023)\n",
        "1. [X] Use the new dataloader to train the model (1/2/2023)\n",
        "1. [X] Use new transformer for CIRCLe model (1/3/2023)\n",
        "1. [ ] test using different base models\n",
        "1. [ ] test that adding dropout might help with overfitting\n",
        "1. [X] Add more metrics such as precision and recall (1/4/2023)\n",
        "1. [ ] add fairness metrics\n",
        "1. [ ] add confusion matrics\n",
        "1. [ ] add sensitivity and specificity\n",
        "1. [ ] add metrics for each class\n",
        "1. [ ] (optional) Go back and download and use larger datasets\n",
        "1. [ ] (optional) Run Fitzpatrick on larger datasets(currently using the test set from isic 2018 task 3)\n",
        "1. [ ] The dataloaders need to be split stratified different than the current \"training, validation, and test\" as given from https://challenge.isic-archive.com/data/#2018 based on skin types. 12/30/2022 - I think this is done BUT we might consider doing k-fold approach which adds another layer of complexity to the dataloaders"
      ],
      "metadata": {
        "id": "ajchIOEXMH4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the environment"
      ],
      "metadata": {
        "id": "1IqTnocWPMkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX3pAmwlWnf5",
        "outputId": "18d3b49d-ff48-4cb9-fa70-a4b9ba298075"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs & imports"
      ],
      "metadata": {
        "id": "yzsWv7g9MB87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download latest code"
      ],
      "metadata": {
        "id": "cLWa0BAdPQBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kQ5LposJzeZ",
        "outputId": "7c8dc795-a35e-4bf7-db7e-13a4f4634530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CIRCLe'...\n",
            "remote: Enumerating objects: 458, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 458 (delta 64), reused 88 (delta 38), pack-reused 339\u001b[K\n",
            "Receiving objects: 100% (458/458), 1.81 MiB | 23.12 MiB/s, done.\n",
            "Resolving deltas: 100% (230/230), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/acorbin3/CIRCLe.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./CIRCLe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9eGp7LOm90J",
        "outputId": "86a65069-2a92-437f-a053-09878cde256e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CIRCLe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- models/circle.py"
      ],
      "metadata": {
        "id": "OgCG317Q6qru"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNNuLRyKQ7-",
        "outputId": "c060a55b-f684-4413-ccc2-f7901b87d721"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r ./requirements.txt"
      ],
      "metadata": {
        "id": "DWzYtBAIKvuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9a5baf-55d5-4283-c368-39e575dda188"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23.2\n",
            "  Downloading numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.4.4\n",
            "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.2.0\n",
            "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==1.1.2\n",
            "  Downloading scikit_learn-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow==2.9.2 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 5)) (2.9.2)\n",
            "Collecting torch==1.12.1\n",
            "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.1\n",
            "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 8)) (4.64.1)\n",
            "Collecting derm-ita>=0.0.8\n",
            "  Downloading derm_ita-0.0.8-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2022.7)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.51.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (21.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.29.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (14.0.6)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.25.1)\n",
            "Collecting patchify>=0.2.3\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Collecting scikit-image>=0.19\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.38.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2022.10.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.0.9)\n",
            "Collecting scipy>=1.3.2\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (5.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.2.2)\n",
            "Installing collected packages: torch, Pillow, numpy, torchvision, scipy, patchify, pandas, scikit_learn, scikit-image, derm-ita\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.2.0 derm-ita-0.0.8 numpy-1.23.2 pandas-1.4.4 patchify-0.2.3 scikit-image-0.19.3 scikit_learn-1.1.2 scipy-1.10.0 torch-1.12.1 torchvision-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This next block of code will be needed if you get this error: **\n",
        "\n",
        "A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation. The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70."
      ],
      "metadata": {
        "id": "1q3ovxukTHlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "qhckJLuHSlkS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IF ERROR, RESTART RUNTIME due to derm-ita lib\n",
        "This is due to derm-ita using newer libaries than the Google Colab default(during this time of 12/24/2022)"
      ],
      "metadata": {
        "id": "pB8smeonMesX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train CIRCLe model "
      ],
      "metadata": {
        "id": "fKUV22LhVzBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir ./saved\n",
        "%mkdir ./saved/model"
      ],
      "metadata": {
        "id": "08ngcZp9m1-S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- main.py\n",
        "!git checkout -- organize_data/isic_2018/dataset.py"
      ],
      "metadata": {
        "id": "y8uJMyX54Qti"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akY1e2Sh-FdU",
        "outputId": "ef749c35-14aa-4f24-bf6f-d6375ef5eee9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --use_reg_loss False --model cnn --dataset isic2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH5FKsbclkje",
        "outputId": "5aa4090b-ca86-4ad2-a284-9c2025893359"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flags:\n",
            "\talpha: 0.1\n",
            "\tbase: vgg16\n",
            "\tbatch_size: 32\n",
            "\tdata_dir: ../data/fitz17k/images/all/\n",
            "\tdataset: isic2018\n",
            "\tepochs: 100\n",
            "\tgan_path: saved/stargan/\n",
            "\thidden_dim: 256\n",
            "\tlr: 0.001\n",
            "\tmodel: cnn\n",
            "\tmodel_save_dir: saved/model/\n",
            "\tnum_classes: 7\n",
            "\tseed: 1\n",
            "\tuse_reg_loss: True\n",
            "\tweight_decay: 0.001\n",
            "isic2018 images already downloaded\n",
            "isic 2018 masks already downladed\n",
            "Donloading isic 2018 ground truth classification data\n",
            "Creating dataframe\n",
            "\t Looking for cached dataframe\n",
            "\t\t organize_data/isic_2018/saved_data_2022_12_27_isic_2018.csv\n",
            "Creating dataframe. Complete!\n",
            "Splitting up the dataset into train,test, validation datasets\n",
            "fizpatrick_skin_type: 1 8001\n",
            "\t train 6400\n",
            "\t test 800\n",
            "\t val 801\n",
            "fizpatrick_skin_type: 2 1049\n",
            "\t train 839\n",
            "\t test 105\n",
            "\t val 105\n",
            "fizpatrick_skin_type: 3 513\n",
            "\t train 410\n",
            "\t test 51\n",
            "\t val 52\n",
            "fizpatrick_skin_type: 4 182\n",
            "\t train 145\n",
            "\t test 18\n",
            "\t val 19\n",
            "fizpatrick_skin_type: 5 107\n",
            "\t train 85\n",
            "\t test 11\n",
            "\t val 11\n",
            "fizpatrick_skin_type: 6 163\n",
            "\t train 130\n",
            "\t test 16\n",
            "\t val 17\n",
            "total_train: 8009 79.9700449326011\n",
            "total_test: 1001 9.995007488766849\n",
            "total_val: 1005 10.034947578632051\n",
            "train size: 8009\n",
            "test size: 1001\n",
            "val size: 1005\n",
            "\ttrain: skin type 1 : 6400\n",
            "\ttrain: skin type 2 : 839\n",
            "\ttrain: skin type 3 : 410\n",
            "\ttrain: skin type 4 : 145\n",
            "\ttrain: skin type 5 : 85\n",
            "\ttrain: skin type 6 : 130\n",
            "----\n",
            "\ttest: skin type 1 : 800\n",
            "\ttest: skin type 2 : 105\n",
            "\ttest: skin type 3 : 51\n",
            "\ttest: skin type 4 : 18\n",
            "\ttest: skin type 5 : 11\n",
            "\ttest: skin type 6 : 16\n",
            "----\n",
            "\tval: skin type 1 : 801\n",
            "\tval: skin type 2 : 105\n",
            "\tval: skin type 3 : 52\n",
            "\tval: skin type 4 : 19\n",
            "\tval: skin type 5 : 11\n",
            "\tval: skin type 6 : 17\n",
            "train size: 8009\n",
            "val size: 1005\n",
            "train skin types: [1 2 3 4 5 6]\n",
            "val skin types: [1 2 3 4 5 6]\n",
            "train skin conditions: 7\n",
            "val skin conditions: 7\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 128, 128]             448\n",
            "              ReLU-2         [-1, 16, 128, 128]               0\n",
            "         MaxPool2d-3           [-1, 16, 64, 64]               0\n",
            "            Conv2d-4           [-1, 32, 64, 64]           4,640\n",
            "              ReLU-5           [-1, 32, 64, 64]               0\n",
            "         MaxPool2d-6           [-1, 32, 32, 32]               0\n",
            "            Conv2d-7           [-1, 64, 32, 32]          18,496\n",
            "              ReLU-8           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-9           [-1, 64, 16, 16]               0\n",
            "          Flatten-10                [-1, 16384]               0\n",
            "           Linear-11                   [-1, 64]       1,048,640\n",
            "          Dropout-12                   [-1, 64]               0\n",
            "           Linear-13                    [-1, 7]             455\n",
            "================================================================\n",
            "Total params: 1,072,679\n",
            "Trainable params: 1,072,679\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 8.00\n",
            "Params size (MB): 4.09\n",
            "Estimated Total Size (MB): 12.28\n",
            "----------------------------------------------------------------\n",
            "Epoch 0: Best val loss inf, Best val acc 0.0000, best val recall 0.0000, best val precision 0.0000\n",
            "\t>>> Training: Loss 1.1591, Reg 0.000, Acc 0.6640, precision: 0.6640, recall0.6640\n",
            "\t>>> Val.    : Loss 1.2005, Reg 0.0003, Acc 0.6653, precision: 0.6653, recall0.6653\n",
            "Saved model with highest acc ...\n",
            "Epoch 1: Best val loss 1.2005, Best val acc 0.6653, best val recall 0.6653, best val precision 0.6653\n",
            "\t>>> Training: Loss 1.1512, Reg 0.000, Acc 0.6654, precision: 0.6654, recall0.6654\n",
            "\t>>> Val.    : Loss 1.1905, Reg 0.0002, Acc 0.6643, precision: 0.6643, recall0.6643\n",
            "Epoch 2: Best val loss 1.1905, Best val acc 0.6653, best val recall 0.6653, best val precision 0.6653\n",
            "\t>>> Training: Loss 1.1482, Reg 0.000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "\t>>> Val.    : Loss 1.1901, Reg 0.0002, Acc 0.6640, precision: 0.6640, recall0.6640\n",
            "Epoch 3: Best val loss 1.1901, Best val acc 0.6653, best val recall 0.6653, best val precision 0.6653\n",
            "\t>>> Training: Loss 1.1452, Reg 0.000, Acc 0.6661, precision: 0.6661, recall0.6661\n",
            "\t>>> Val.    : Loss 1.1932, Reg 0.0001, Acc 0.6641, precision: 0.6641, recall0.6641\n",
            "Epoch 4: Best val loss 1.1901, Best val acc 0.6653, best val recall 0.6653, best val precision 0.6653\n",
            "\t>>> Training: Loss 1.1434, Reg 0.000, Acc 0.6662, precision: 0.6662, recall0.6662\n",
            "\t>>> Val.    : Loss 1.1966, Reg 0.0001, Acc 0.6647, precision: 0.6647, recall0.6647\n",
            "Epoch 5: Best val loss 1.1901, Best val acc 0.6653, best val recall 0.6653, best val precision 0.6653\n",
            "\t>>> Training: Loss 1.1420, Reg 0.000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "\t>>> Val.    : Loss 1.1986, Reg 0.0001, Acc 0.6655, precision: 0.6655, recall0.6655\n",
            "Saved model with highest acc ...\n",
            "Epoch 6: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1413, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2016, Reg 0.0001, Acc 0.6652, precision: 0.6652, recall0.6652\n",
            "Epoch 7: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1403, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2036, Reg 0.0001, Acc 0.6652, precision: 0.6652, recall0.6652\n",
            "Epoch 8: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1396, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2065, Reg 0.0001, Acc 0.6648, precision: 0.6648, recall0.6648\n",
            "Epoch 9: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1390, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2091, Reg 0.0001, Acc 0.6648, precision: 0.6648, recall0.6648\n",
            "Epoch 10: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1384, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2082, Reg 0.0001, Acc 0.6650, precision: 0.6650, recall0.6650\n",
            "Epoch 11: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1377, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2074, Reg 0.0001, Acc 0.6652, precision: 0.6652, recall0.6652\n",
            "Epoch 12: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1367, Reg 0.000, Acc 0.6666, precision: 0.6666, recall0.6666\n",
            "\t>>> Val.    : Loss 1.2051, Reg 0.0005, Acc 0.6654, precision: 0.6654, recall0.6654\n",
            "Epoch 13: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1349, Reg 0.000, Acc 0.6667, precision: 0.6667, recall0.6667\n",
            "\t>>> Val.    : Loss 1.2105, Reg 0.0028, Acc 0.6650, precision: 0.6650, recall0.6650\n",
            "Epoch 14: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1328, Reg 0.000, Acc 0.6669, precision: 0.6669, recall0.6669\n",
            "\t>>> Val.    : Loss 1.2185, Reg 0.0087, Acc 0.6639, precision: 0.6639, recall0.6639\n",
            "Epoch 15: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1294, Reg 0.000, Acc 0.6673, precision: 0.6673, recall0.6673\n",
            "\t>>> Val.    : Loss 1.2378, Reg 0.0236, Acc 0.6605, precision: 0.6605, recall0.6605\n",
            "Epoch 16: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1253, Reg 0.000, Acc 0.6678, precision: 0.6678, recall0.6678\n",
            "\t>>> Val.    : Loss 1.2544, Reg 0.0397, Acc 0.6586, precision: 0.6586, recall0.6586\n",
            "Epoch 17: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1205, Reg 0.000, Acc 0.6685, precision: 0.6685, recall0.6685\n",
            "\t>>> Val.    : Loss 1.2632, Reg 0.0469, Acc 0.6581, precision: 0.6581, recall0.6581\n",
            "Epoch 18: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1144, Reg 0.000, Acc 0.6695, precision: 0.6695, recall0.6695\n",
            "\t>>> Val.    : Loss 1.2768, Reg 0.0573, Acc 0.6577, precision: 0.6577, recall0.6577\n",
            "Epoch 19: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.1070, Reg 0.000, Acc 0.6711, precision: 0.6711, recall0.6711\n",
            "\t>>> Val.    : Loss 1.2958, Reg 0.0713, Acc 0.6569, precision: 0.6569, recall0.6569\n",
            "Epoch 20: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.0985, Reg 0.000, Acc 0.6730, precision: 0.6730, recall0.6730\n",
            "\t>>> Val.    : Loss 1.3172, Reg 0.0873, Acc 0.6550, precision: 0.6550, recall0.6550\n",
            "Epoch 21: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.0889, Reg 0.000, Acc 0.6752, precision: 0.6752, recall0.6752\n",
            "\t>>> Val.    : Loss 1.3467, Reg 0.1066, Acc 0.6540, precision: 0.6540, recall0.6540\n",
            "Epoch 22: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.0782, Reg 0.000, Acc 0.6777, precision: 0.6777, recall0.6777\n",
            "\t>>> Val.    : Loss 1.3813, Reg 0.1298, Acc 0.6524, precision: 0.6524, recall0.6524\n",
            "Epoch 23: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.0665, Reg 0.000, Acc 0.6805, precision: 0.6805, recall0.6805\n",
            "\t>>> Val.    : Loss 1.4284, Reg 0.1616, Acc 0.6509, precision: 0.6509, recall0.6509\n",
            "Epoch 24: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.0541, Reg 0.000, Acc 0.6838, precision: 0.6838, recall0.6838\n",
            "\t>>> Val.    : Loss 1.4814, Reg 0.2008, Acc 0.6496, precision: 0.6496, recall0.6496\n",
            "Epoch 25: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.0406, Reg 0.000, Acc 0.6873, precision: 0.6873, recall0.6873\n",
            "\t>>> Val.    : Loss 1.5354, Reg 0.2398, Acc 0.6473, precision: 0.6473, recall0.6473\n",
            "Epoch 26: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.0269, Reg 0.000, Acc 0.6908, precision: 0.6908, recall0.6908\n",
            "\t>>> Val.    : Loss 1.6129, Reg 0.2850, Acc 0.6450, precision: 0.6450, recall0.6450\n",
            "Epoch 27: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 1.0129, Reg 0.000, Acc 0.6945, precision: 0.6945, recall0.6945\n",
            "\t>>> Val.    : Loss 1.6884, Reg 0.3295, Acc 0.6421, precision: 0.6421, recall0.6421\n",
            "Epoch 28: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.9985, Reg 0.000, Acc 0.6983, precision: 0.6983, recall0.6983\n",
            "\t>>> Val.    : Loss 1.8006, Reg 0.3848, Acc 0.6412, precision: 0.6412, recall0.6412\n",
            "Epoch 29: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.9849, Reg 0.000, Acc 0.7019, precision: 0.7019, recall0.7019\n",
            "\t>>> Val.    : Loss 1.9161, Reg 0.4445, Acc 0.6404, precision: 0.6404, recall0.6404\n",
            "Epoch 30: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.9721, Reg 0.000, Acc 0.7053, precision: 0.7053, recall0.7053\n",
            "\t>>> Val.    : Loss 2.0275, Reg 0.5040, Acc 0.6391, precision: 0.6391, recall0.6391\n",
            "Epoch 31: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.9591, Reg 0.000, Acc 0.7090, precision: 0.7090, recall0.7090\n",
            "\t>>> Val.    : Loss 2.1294, Reg 0.5526, Acc 0.6371, precision: 0.6371, recall0.6371\n",
            "Epoch 32: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.9455, Reg 0.000, Acc 0.7127, precision: 0.7127, recall0.7127\n",
            "\t>>> Val.    : Loss 2.2235, Reg 0.5995, Acc 0.6355, precision: 0.6355, recall0.6355\n",
            "Epoch 33: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.9323, Reg 0.000, Acc 0.7164, precision: 0.7164, recall0.7164\n",
            "\t>>> Val.    : Loss 2.3088, Reg 0.6438, Acc 0.6344, precision: 0.6344, recall0.6344\n",
            "Epoch 34: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.9184, Reg 0.000, Acc 0.7202, precision: 0.7202, recall0.7202\n",
            "\t>>> Val.    : Loss 2.4127, Reg 0.6949, Acc 0.6330, precision: 0.6330, recall0.6330\n",
            "Epoch 35: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.9049, Reg 0.000, Acc 0.7240, precision: 0.7240, recall0.7240\n",
            "\t>>> Val.    : Loss 2.5135, Reg 0.7437, Acc 0.6311, precision: 0.6311, recall0.6311\n",
            "Epoch 36: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.8924, Reg 0.000, Acc 0.7276, precision: 0.7276, recall0.7276\n",
            "\t>>> Val.    : Loss 2.6037, Reg 0.7791, Acc 0.6300, precision: 0.6300, recall0.6300\n",
            "Epoch 37: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.8799, Reg 0.000, Acc 0.7311, precision: 0.7311, recall0.7311\n",
            "\t>>> Val.    : Loss 2.7008, Reg 0.8134, Acc 0.6284, precision: 0.6284, recall0.6284\n",
            "Epoch 38: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.8671, Reg 0.000, Acc 0.7347, precision: 0.7347, recall0.7347\n",
            "\t>>> Val.    : Loss 2.8135, Reg 0.8565, Acc 0.6276, precision: 0.6276, recall0.6276\n",
            "Epoch 39: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.8545, Reg 0.000, Acc 0.7383, precision: 0.7383, recall0.7383\n",
            "\t>>> Val.    : Loss 2.9266, Reg 0.9081, Acc 0.6273, precision: 0.6273, recall0.6273\n",
            "Epoch 40: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.8422, Reg 0.000, Acc 0.7419, precision: 0.7419, recall0.7419\n",
            "\t>>> Val.    : Loss 3.0234, Reg 0.9416, Acc 0.6265, precision: 0.6265, recall0.6265\n",
            "Epoch 41: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.8300, Reg 0.000, Acc 0.7454, precision: 0.7454, recall0.7454\n",
            "\t>>> Val.    : Loss 3.1153, Reg 0.9797, Acc 0.6257, precision: 0.6257, recall0.6257\n",
            "Epoch 42: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.8177, Reg 0.000, Acc 0.7490, precision: 0.7490, recall0.7490\n",
            "\t>>> Val.    : Loss 3.2194, Reg 1.0250, Acc 0.6247, precision: 0.6247, recall0.6247\n",
            "Epoch 43: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.8059, Reg 0.000, Acc 0.7524, precision: 0.7524, recall0.7524\n",
            "\t>>> Val.    : Loss 3.3251, Reg 1.0683, Acc 0.6242, precision: 0.6242, recall0.6242\n",
            "Epoch 44: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.7940, Reg 0.000, Acc 0.7559, precision: 0.7559, recall0.7559\n",
            "\t>>> Val.    : Loss 3.4244, Reg 1.1097, Acc 0.6236, precision: 0.6236, recall0.6236\n",
            "Epoch 45: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.7827, Reg 0.000, Acc 0.7592, precision: 0.7592, recall0.7592\n",
            "\t>>> Val.    : Loss 3.5246, Reg 1.1537, Acc 0.6231, precision: 0.6231, recall0.6231\n",
            "Epoch 46: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.7713, Reg 0.000, Acc 0.7625, precision: 0.7625, recall0.7625\n",
            "\t>>> Val.    : Loss 3.6183, Reg 1.1932, Acc 0.6222, precision: 0.6222, recall0.6222\n",
            "Epoch 47: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.7603, Reg 0.000, Acc 0.7658, precision: 0.7658, recall0.7658\n",
            "\t>>> Val.    : Loss 3.7188, Reg 1.2405, Acc 0.6215, precision: 0.6215, recall0.6215\n",
            "Epoch 48: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.7494, Reg 0.000, Acc 0.7690, precision: 0.7690, recall0.7690\n",
            "\t>>> Val.    : Loss 3.8190, Reg 1.2856, Acc 0.6211, precision: 0.6211, recall0.6211\n",
            "Epoch 49: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.7395, Reg 0.000, Acc 0.7719, precision: 0.7719, recall0.7719\n",
            "\t>>> Val.    : Loss 3.9138, Reg 1.3293, Acc 0.6203, precision: 0.6203, recall0.6203\n",
            "Epoch 50: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.7290, Reg 0.000, Acc 0.7750, precision: 0.7750, recall0.7750\n",
            "\t>>> Val.    : Loss 4.0105, Reg 1.3730, Acc 0.6198, precision: 0.6198, recall0.6198\n",
            "Epoch 51: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.7188, Reg 0.000, Acc 0.7781, precision: 0.7781, recall0.7781\n",
            "\t>>> Val.    : Loss 4.1105, Reg 1.4193, Acc 0.6195, precision: 0.6195, recall0.6195\n",
            "Epoch 52: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.7086, Reg 0.000, Acc 0.7812, precision: 0.7812, recall0.7812\n",
            "\t>>> Val.    : Loss 4.2048, Reg 1.4624, Acc 0.6192, precision: 0.6192, recall0.6192\n",
            "Epoch 53: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6987, Reg 0.000, Acc 0.7841, precision: 0.7841, recall0.7841\n",
            "\t>>> Val.    : Loss 4.3079, Reg 1.5149, Acc 0.6188, precision: 0.6188, recall0.6188\n",
            "Epoch 54: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6896, Reg 0.000, Acc 0.7870, precision: 0.7870, recall0.7870\n",
            "\t>>> Val.    : Loss 4.4017, Reg 1.5704, Acc 0.6183, precision: 0.6183, recall0.6183\n",
            "Epoch 55: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6806, Reg 0.000, Acc 0.7896, precision: 0.7896, recall0.7896\n",
            "\t>>> Val.    : Loss 4.4813, Reg 1.6167, Acc 0.6179, precision: 0.6179, recall0.6179\n",
            "Epoch 56: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6717, Reg 0.000, Acc 0.7923, precision: 0.7923, recall0.7923\n",
            "\t>>> Val.    : Loss 4.5553, Reg 1.6575, Acc 0.6171, precision: 0.6171, recall0.6171\n",
            "Epoch 57: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6626, Reg 0.000, Acc 0.7950, precision: 0.7950, recall0.7950\n",
            "\t>>> Val.    : Loss 4.6434, Reg 1.7000, Acc 0.6167, precision: 0.6167, recall0.6167\n",
            "Epoch 58: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6537, Reg 0.000, Acc 0.7977, precision: 0.7977, recall0.7977\n",
            "\t>>> Val.    : Loss 4.7238, Reg 1.7498, Acc 0.6162, precision: 0.6162, recall0.6162\n",
            "Epoch 59: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6455, Reg 0.000, Acc 0.8003, precision: 0.8003, recall0.8003\n",
            "\t>>> Val.    : Loss 4.8097, Reg 1.8092, Acc 0.6156, precision: 0.6156, recall0.6156\n",
            "Epoch 60: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6373, Reg 0.000, Acc 0.8028, precision: 0.8028, recall0.8028\n",
            "\t>>> Val.    : Loss 4.8930, Reg 1.8663, Acc 0.6149, precision: 0.6149, recall0.6149\n",
            "Epoch 61: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6293, Reg 0.000, Acc 0.8052, precision: 0.8052, recall0.8052\n",
            "\t>>> Val.    : Loss 4.9846, Reg 1.9225, Acc 0.6142, precision: 0.6142, recall0.6142\n",
            "Epoch 62: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6216, Reg 0.000, Acc 0.8076, precision: 0.8076, recall0.8076\n",
            "\t>>> Val.    : Loss 5.0684, Reg 1.9741, Acc 0.6131, precision: 0.6131, recall0.6131\n",
            "Epoch 63: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6140, Reg 0.000, Acc 0.8099, precision: 0.8099, recall0.8099\n",
            "\t>>> Val.    : Loss 5.1535, Reg 2.0287, Acc 0.6126, precision: 0.6126, recall0.6126\n",
            "Epoch 64: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.6065, Reg 0.000, Acc 0.8122, precision: 0.8122, recall0.8122\n",
            "\t>>> Val.    : Loss 5.2408, Reg 2.0897, Acc 0.6121, precision: 0.6121, recall0.6121\n",
            "Epoch 65: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5992, Reg 0.000, Acc 0.8145, precision: 0.8145, recall0.8145\n",
            "\t>>> Val.    : Loss 5.3207, Reg 2.1461, Acc 0.6112, precision: 0.6112, recall0.6112\n",
            "Epoch 66: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5917, Reg 0.000, Acc 0.8168, precision: 0.8168, recall0.8168\n",
            "\t>>> Val.    : Loss 5.4173, Reg 2.2073, Acc 0.6106, precision: 0.6106, recall0.6106\n",
            "Epoch 67: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5845, Reg 0.000, Acc 0.8190, precision: 0.8190, recall0.8190\n",
            "\t>>> Val.    : Loss 5.4961, Reg 2.2598, Acc 0.6099, precision: 0.6099, recall0.6099\n",
            "Epoch 68: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5775, Reg 0.000, Acc 0.8210, precision: 0.8210, recall0.8210\n",
            "\t>>> Val.    : Loss 5.5844, Reg 2.3145, Acc 0.6093, precision: 0.6093, recall0.6093\n",
            "Epoch 69: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5712, Reg 0.000, Acc 0.8231, precision: 0.8231, recall0.8231\n",
            "\t>>> Val.    : Loss 5.6828, Reg 2.3780, Acc 0.6089, precision: 0.6089, recall0.6089\n",
            "Epoch 70: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5648, Reg 0.000, Acc 0.8250, precision: 0.8250, recall0.8250\n",
            "\t>>> Val.    : Loss 5.7847, Reg 2.4398, Acc 0.6085, precision: 0.6085, recall0.6085\n",
            "Epoch 71: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5584, Reg 0.000, Acc 0.8270, precision: 0.8270, recall0.8270\n",
            "\t>>> Val.    : Loss 5.8804, Reg 2.5065, Acc 0.6079, precision: 0.6079, recall0.6079\n",
            "Epoch 72: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5520, Reg 0.000, Acc 0.8290, precision: 0.8290, recall0.8290\n",
            "\t>>> Val.    : Loss 5.9862, Reg 2.5730, Acc 0.6074, precision: 0.6074, recall0.6074\n",
            "Epoch 73: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5459, Reg 0.000, Acc 0.8308, precision: 0.8308, recall0.8308\n",
            "\t>>> Val.    : Loss 6.0764, Reg 2.6267, Acc 0.6068, precision: 0.6068, recall0.6068\n",
            "Epoch 74: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5397, Reg 0.000, Acc 0.8328, precision: 0.8328, recall0.8328\n",
            "\t>>> Val.    : Loss 6.1795, Reg 2.6851, Acc 0.6063, precision: 0.6063, recall0.6063\n",
            "Epoch 75: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5338, Reg 0.000, Acc 0.8346, precision: 0.8346, recall0.8346\n",
            "\t>>> Val.    : Loss 6.2793, Reg 2.7487, Acc 0.6059, precision: 0.6059, recall0.6059\n",
            "Epoch 76: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5281, Reg 0.000, Acc 0.8363, precision: 0.8363, recall0.8363\n",
            "\t>>> Val.    : Loss 6.3762, Reg 2.8183, Acc 0.6054, precision: 0.6054, recall0.6054\n",
            "Epoch 77: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5229, Reg 0.000, Acc 0.8380, precision: 0.8380, recall0.8380\n",
            "\t>>> Val.    : Loss 6.4687, Reg 2.8805, Acc 0.6050, precision: 0.6050, recall0.6050\n",
            "Epoch 78: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5178, Reg 0.000, Acc 0.8396, precision: 0.8396, recall0.8396\n",
            "\t>>> Val.    : Loss 6.5660, Reg 2.9363, Acc 0.6046, precision: 0.6046, recall0.6046\n",
            "Epoch 79: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5124, Reg 0.000, Acc 0.8413, precision: 0.8413, recall0.8413\n",
            "\t>>> Val.    : Loss 6.6617, Reg 2.9895, Acc 0.6043, precision: 0.6043, recall0.6043\n",
            "Epoch 80: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5070, Reg 0.000, Acc 0.8430, precision: 0.8430, recall0.8430\n",
            "\t>>> Val.    : Loss 6.7582, Reg 3.0495, Acc 0.6040, precision: 0.6040, recall0.6040\n",
            "Epoch 81: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.5019, Reg 0.000, Acc 0.8446, precision: 0.8446, recall0.8446\n",
            "\t>>> Val.    : Loss 6.8533, Reg 3.1177, Acc 0.6036, precision: 0.6036, recall0.6036\n",
            "Epoch 82: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4969, Reg 0.000, Acc 0.8461, precision: 0.8461, recall0.8461\n",
            "\t>>> Val.    : Loss 6.9584, Reg 3.1876, Acc 0.6033, precision: 0.6033, recall0.6033\n",
            "Epoch 83: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4920, Reg 0.000, Acc 0.8476, precision: 0.8476, recall0.8476\n",
            "\t>>> Val.    : Loss 7.0619, Reg 3.2571, Acc 0.6029, precision: 0.6029, recall0.6029\n",
            "Epoch 84: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4872, Reg 0.000, Acc 0.8492, precision: 0.8492, recall0.8492\n",
            "\t>>> Val.    : Loss 7.1569, Reg 3.3193, Acc 0.6024, precision: 0.6024, recall0.6024\n",
            "Epoch 85: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4823, Reg 0.000, Acc 0.8507, precision: 0.8507, recall0.8507\n",
            "\t>>> Val.    : Loss 7.2571, Reg 3.3792, Acc 0.6020, precision: 0.6020, recall0.6020\n",
            "Epoch 86: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4776, Reg 0.000, Acc 0.8522, precision: 0.8522, recall0.8522\n",
            "\t>>> Val.    : Loss 7.3418, Reg 3.4404, Acc 0.6017, precision: 0.6017, recall0.6017\n",
            "Epoch 87: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4731, Reg 0.000, Acc 0.8536, precision: 0.8536, recall0.8536\n",
            "\t>>> Val.    : Loss 7.4483, Reg 3.5191, Acc 0.6014, precision: 0.6014, recall0.6014\n",
            "Epoch 88: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4689, Reg 0.000, Acc 0.8550, precision: 0.8550, recall0.8550\n",
            "\t>>> Val.    : Loss 7.5396, Reg 3.5864, Acc 0.6011, precision: 0.6011, recall0.6011\n",
            "Epoch 89: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4649, Reg 0.000, Acc 0.8563, precision: 0.8563, recall0.8563\n",
            "\t>>> Val.    : Loss 7.6160, Reg 3.6332, Acc 0.6008, precision: 0.6008, recall0.6008\n",
            "Epoch 90: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4606, Reg 0.000, Acc 0.8576, precision: 0.8576, recall0.8576\n",
            "\t>>> Val.    : Loss 7.7004, Reg 3.6967, Acc 0.6002, precision: 0.6002, recall0.6002\n",
            "Epoch 91: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4564, Reg 0.000, Acc 0.8589, precision: 0.8589, recall0.8589\n",
            "\t>>> Val.    : Loss 7.7788, Reg 3.7547, Acc 0.5999, precision: 0.5999, recall0.5999\n",
            "Epoch 92: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4522, Reg 0.000, Acc 0.8603, precision: 0.8603, recall0.8603\n",
            "\t>>> Val.    : Loss 7.8634, Reg 3.8065, Acc 0.5996, precision: 0.5996, recall0.5996\n",
            "Epoch 93: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4481, Reg 0.000, Acc 0.8616, precision: 0.8616, recall0.8616\n",
            "\t>>> Val.    : Loss 7.9225, Reg 3.8537, Acc 0.5991, precision: 0.5991, recall0.5991\n",
            "Epoch 94: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4439, Reg 0.000, Acc 0.8629, precision: 0.8629, recall0.8629\n",
            "\t>>> Val.    : Loss 7.9930, Reg 3.8949, Acc 0.5986, precision: 0.5986, recall0.5986\n",
            "Epoch 95: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4400, Reg 0.000, Acc 0.8641, precision: 0.8641, recall0.8641\n",
            "\t>>> Val.    : Loss 8.0666, Reg 3.9407, Acc 0.5981, precision: 0.5981, recall0.5981\n",
            "Epoch 96: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4360, Reg 0.000, Acc 0.8653, precision: 0.8653, recall0.8653\n",
            "\t>>> Val.    : Loss 8.1393, Reg 3.9898, Acc 0.5978, precision: 0.5978, recall0.5978\n",
            "Epoch 97: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4323, Reg 0.000, Acc 0.8665, precision: 0.8665, recall0.8665\n",
            "\t>>> Val.    : Loss 8.2066, Reg 4.0350, Acc 0.5974, precision: 0.5974, recall0.5974\n",
            "Epoch 98: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4284, Reg 0.000, Acc 0.8678, precision: 0.8678, recall0.8678\n",
            "\t>>> Val.    : Loss 8.2816, Reg 4.0800, Acc 0.5970, precision: 0.5970, recall0.5970\n",
            "Epoch 99: Best val loss 1.1901, Best val acc 0.6655, best val recall 0.6655, best val precision 0.6655\n",
            "\t>>> Training: Loss 0.4246, Reg 0.000, Acc 0.8690, precision: 0.8690, recall0.8690\n",
            "\t>>> Val.    : Loss 8.3534, Reg 4.1304, Acc 0.5967, precision: 0.5967, recall0.5967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%mkdir /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints"
      ],
      "metadata": {
        "id": "O4m8fvzN-oJN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UULfzcFrynFz",
        "outputId": "86b1fd84-adeb-4112-95e4-8d75075b9465"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cp ./saved/model/epoch97_acc_0.762.ckpt /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints/CIRCLE/mobilenetv3l/"
      ],
      "metadata": {
        "id": "1hFw2rQB-7np"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}