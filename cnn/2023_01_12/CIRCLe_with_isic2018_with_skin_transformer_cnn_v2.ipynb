{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_HSnGPDTmtQqL19RJaSZ9opYOjST_pFh",
      "authorship_tag": "ABX9TyP1aJ07Z0G0g+jQhP97C3Ne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamCorbinFAUPhD/CIRCLe-experiments/blob/main/cnn/2023_01_12/CIRCLe_with_isic2018_with_skin_transformer_cnn_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment notes\n",
        "\n",
        "- date: 2023/01/11 8:26am\n",
        "- base model: simple cnn \n",
        "- Trying to add and test simple CNN\n",
        "- 16 hidden layer\n",
        "- .2 drop out\n",
        "\n",
        "Results: \n",
        "- overfitting \n"
      ],
      "metadata": {
        "id": "5K9KcPXtTmUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "This notebook is used to modify the implementation of CIRCLe from this paper : [CIRCLe: Color Invariant Representation\n",
        "Learning for Unbiased Classification of Skin\n",
        "Lesions](https://arxiv.org/pdf/2208.13528.pdf)\n",
        "\n",
        "Their github repo is : https://github.com/arezou-pakzad/CIRCLe\n",
        "\n",
        "This paper uses the Fitzpatrick17k dataset which can be obtained here: https://github.com/mattgroh/fitzpatrick17k\n",
        "\n",
        "For these set of experiments we will use the ISIC 2017 dataset from: https://github.com/manideep2510/melanoma_segmentation.git "
      ],
      "metadata": {
        "id": "jCpy2CqVJ-VI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO list\n",
        "\n",
        "1. [X] Download 2018 dataset\n",
        "1. [X] Analize dataset to get Fitzpatrick info. \n",
        "1. [X] Save off Fitzpatrick info data so we dont have to do it every time\n",
        "1. [X] load cached fitzpatrick data\n",
        "1. [X] Create masks uing https://github.com/DebeshJha/2020-CBMS-DoubleU-Net Because Task 3 for 2018 doesnt havent masks. Trick was to get the higher end GPU and ram (12/29/2022)\n",
        "1. [X] Create pytorch dataloader for ISIC 2018 dataset including loading masks, images, diagnossis, fitzpatrick type for training (12/30/2022) needed to create custom split function\n",
        "1. [X] Create dataloaders for test and validation  (12/30/2022)\n",
        "1. [X] Added jupiter notebook download code into the github repo (1/1/2023)\n",
        "1. [X] plug in dataloader into CIRCLe main file (1/1/2023)\n",
        "1. [X] Figure out how to transform image and mask the same from the dataloader (1/2/2023)\n",
        "1. [X] Use the new dataloader to train the model (1/2/2023)\n",
        "1. [X] Use new transformer for CIRCLe model (1/3/2023)\n",
        "1. [ ] test using different base models\n",
        "1. [ ] test that adding dropout might help with overfitting\n",
        "1. [X] Add more metrics such as precision and recall (1/4/2023)\n",
        "1. [ ] add fairness metrics\n",
        "1. [ ] add confusion matrics\n",
        "1. [ ] add sensitivity and specificity\n",
        "1. [ ] add metrics for each class\n",
        "1. [ ] (optional) Go back and download and use larger datasets\n",
        "1. [ ] (optional) Run Fitzpatrick on larger datasets(currently using the test set from isic 2018 task 3)\n",
        "1. [ ] The dataloaders need to be split stratified different than the current \"training, validation, and test\" as given from https://challenge.isic-archive.com/data/#2018 based on skin types. 12/30/2022 - I think this is done BUT we might consider doing k-fold approach which adds another layer of complexity to the dataloaders"
      ],
      "metadata": {
        "id": "ajchIOEXMH4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the environment"
      ],
      "metadata": {
        "id": "1IqTnocWPMkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX3pAmwlWnf5",
        "outputId": "18d3b49d-ff48-4cb9-fa70-a4b9ba298075"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs & imports"
      ],
      "metadata": {
        "id": "yzsWv7g9MB87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download latest code"
      ],
      "metadata": {
        "id": "cLWa0BAdPQBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kQ5LposJzeZ",
        "outputId": "7c8dc795-a35e-4bf7-db7e-13a4f4634530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CIRCLe'...\n",
            "remote: Enumerating objects: 458, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 458 (delta 64), reused 88 (delta 38), pack-reused 339\u001b[K\n",
            "Receiving objects: 100% (458/458), 1.81 MiB | 23.12 MiB/s, done.\n",
            "Resolving deltas: 100% (230/230), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/acorbin3/CIRCLe.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./CIRCLe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9eGp7LOm90J",
        "outputId": "86a65069-2a92-437f-a053-09878cde256e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CIRCLe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- models/circle.py"
      ],
      "metadata": {
        "id": "OgCG317Q6qru"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNNuLRyKQ7-",
        "outputId": "c060a55b-f684-4413-ccc2-f7901b87d721"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r ./requirements.txt"
      ],
      "metadata": {
        "id": "DWzYtBAIKvuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9a5baf-55d5-4283-c368-39e575dda188"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23.2\n",
            "  Downloading numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.4.4\n",
            "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.2.0\n",
            "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==1.1.2\n",
            "  Downloading scikit_learn-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow==2.9.2 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 5)) (2.9.2)\n",
            "Collecting torch==1.12.1\n",
            "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.1\n",
            "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 8)) (4.64.1)\n",
            "Collecting derm-ita>=0.0.8\n",
            "  Downloading derm_ita-0.0.8-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2022.7)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.51.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (21.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.29.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (14.0.6)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.25.1)\n",
            "Collecting patchify>=0.2.3\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Collecting scikit-image>=0.19\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.38.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2022.10.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.0.9)\n",
            "Collecting scipy>=1.3.2\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (5.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.2.2)\n",
            "Installing collected packages: torch, Pillow, numpy, torchvision, scipy, patchify, pandas, scikit_learn, scikit-image, derm-ita\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.2.0 derm-ita-0.0.8 numpy-1.23.2 pandas-1.4.4 patchify-0.2.3 scikit-image-0.19.3 scikit_learn-1.1.2 scipy-1.10.0 torch-1.12.1 torchvision-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This next block of code will be needed if you get this error: **\n",
        "\n",
        "A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation. The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70."
      ],
      "metadata": {
        "id": "1q3ovxukTHlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "qhckJLuHSlkS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IF ERROR, RESTART RUNTIME due to derm-ita lib\n",
        "This is due to derm-ita using newer libaries than the Google Colab default(during this time of 12/24/2022)"
      ],
      "metadata": {
        "id": "pB8smeonMesX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train CIRCLe model "
      ],
      "metadata": {
        "id": "fKUV22LhVzBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir ./saved\n",
        "%mkdir ./saved/model"
      ],
      "metadata": {
        "id": "08ngcZp9m1-S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- main.py\n",
        "!git checkout -- organize_data/isic_2018/dataset.py"
      ],
      "metadata": {
        "id": "y8uJMyX54Qti"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akY1e2Sh-FdU",
        "outputId": "ef749c35-14aa-4f24-bf6f-d6375ef5eee9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --use_reg_loss False --model cnn --dataset isic2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH5FKsbclkje",
        "outputId": "6efec44c-4b4c-4f44-95ca-8efcb767fe32"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flags:\n",
            "\talpha: 0.1\n",
            "\tbase: vgg16\n",
            "\tbatch_size: 32\n",
            "\tdata_dir: ../data/fitz17k/images/all/\n",
            "\tdataset: isic2018\n",
            "\tepochs: 100\n",
            "\tgan_path: saved/stargan/\n",
            "\thidden_dim: 256\n",
            "\tlr: 0.001\n",
            "\tmodel: cnn\n",
            "\tmodel_save_dir: saved/model/\n",
            "\tnum_classes: 7\n",
            "\tseed: 1\n",
            "\tuse_reg_loss: True\n",
            "\tweight_decay: 0.001\n",
            "isic2018 images already downloaded\n",
            "isic 2018 masks already downladed\n",
            "Donloading isic 2018 ground truth classification data\n",
            "Creating dataframe\n",
            "\t Looking for cached dataframe\n",
            "\t\t organize_data/isic_2018/saved_data_2022_12_27_isic_2018.csv\n",
            "Creating dataframe. Complete!\n",
            "Splitting up the dataset into train,test, validation datasets\n",
            "fizpatrick_skin_type: 1 8001\n",
            "\t train 6400\n",
            "\t test 800\n",
            "\t val 801\n",
            "fizpatrick_skin_type: 2 1049\n",
            "\t train 839\n",
            "\t test 105\n",
            "\t val 105\n",
            "fizpatrick_skin_type: 3 513\n",
            "\t train 410\n",
            "\t test 51\n",
            "\t val 52\n",
            "fizpatrick_skin_type: 4 182\n",
            "\t train 145\n",
            "\t test 18\n",
            "\t val 19\n",
            "fizpatrick_skin_type: 5 107\n",
            "\t train 85\n",
            "\t test 11\n",
            "\t val 11\n",
            "fizpatrick_skin_type: 6 163\n",
            "\t train 130\n",
            "\t test 16\n",
            "\t val 17\n",
            "total_train: 8009 79.9700449326011\n",
            "total_test: 1001 9.995007488766849\n",
            "total_val: 1005 10.034947578632051\n",
            "train size: 8009\n",
            "test size: 1001\n",
            "val size: 1005\n",
            "\ttrain: skin type 1 : 6400\n",
            "\ttrain: skin type 2 : 839\n",
            "\ttrain: skin type 3 : 410\n",
            "\ttrain: skin type 4 : 145\n",
            "\ttrain: skin type 5 : 85\n",
            "\ttrain: skin type 6 : 130\n",
            "----\n",
            "\ttest: skin type 1 : 800\n",
            "\ttest: skin type 2 : 105\n",
            "\ttest: skin type 3 : 51\n",
            "\ttest: skin type 4 : 18\n",
            "\ttest: skin type 5 : 11\n",
            "\ttest: skin type 6 : 16\n",
            "----\n",
            "\tval: skin type 1 : 801\n",
            "\tval: skin type 2 : 105\n",
            "\tval: skin type 3 : 52\n",
            "\tval: skin type 4 : 19\n",
            "\tval: skin type 5 : 11\n",
            "\tval: skin type 6 : 17\n",
            "train size: 8009\n",
            "val size: 1005\n",
            "train skin types: [1 2 3 4 5 6]\n",
            "val skin types: [1 2 3 4 5 6]\n",
            "train skin conditions: 7\n",
            "val skin conditions: 7\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 128, 128]             448\n",
            "              ReLU-2         [-1, 16, 128, 128]               0\n",
            "         MaxPool2d-3           [-1, 16, 64, 64]               0\n",
            "            Conv2d-4           [-1, 32, 64, 64]           4,640\n",
            "              ReLU-5           [-1, 32, 64, 64]               0\n",
            "         MaxPool2d-6           [-1, 32, 32, 32]               0\n",
            "            Conv2d-7           [-1, 64, 32, 32]          18,496\n",
            "              ReLU-8           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-9           [-1, 64, 16, 16]               0\n",
            "          Flatten-10                [-1, 16384]               0\n",
            "           Linear-11                   [-1, 16]         262,160\n",
            "          Dropout-12                   [-1, 16]               0\n",
            "           Linear-13                    [-1, 7]             119\n",
            "================================================================\n",
            "Total params: 285,863\n",
            "Trainable params: 285,863\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 8.00\n",
            "Params size (MB): 1.09\n",
            "Estimated Total Size (MB): 9.28\n",
            "----------------------------------------------------------------\n",
            "Epoch 0: Best val loss inf, Best val acc 0.0000, best val recall 0.0000, best val precision 0.0000\n",
            "\t>>> Training: Loss 1.1786, Reg 0.000, Acc 0.6636, precision: 0.6636, recall0.6636\n",
            "\t>>> Val.    : Loss 1.1994, Reg 0.0013, Acc 0.6623, precision: 0.6623, recall0.6623\n",
            "Saved model with highest acc ...\n",
            "Epoch 1: Best val loss 1.1994, Best val acc 0.6623, best val recall 0.6623, best val precision 0.6623\n",
            "\t>>> Training: Loss 1.1633, Reg 0.000, Acc 0.6652, precision: 0.6652, recall0.6652\n",
            "\t>>> Val.    : Loss 1.2126, Reg 0.0016, Acc 0.6613, precision: 0.6613, recall0.6613\n",
            "Epoch 2: Best val loss 1.1994, Best val acc 0.6623, best val recall 0.6623, best val precision 0.6623\n",
            "\t>>> Training: Loss 1.1568, Reg 0.000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "\t>>> Val.    : Loss 1.2303, Reg 0.0012, Acc 0.6620, precision: 0.6620, recall0.6620\n",
            "Epoch 3: Best val loss 1.1994, Best val acc 0.6623, best val recall 0.6623, best val precision 0.6623\n",
            "\t>>> Training: Loss 1.1529, Reg 0.000, Acc 0.6660, precision: 0.6660, recall0.6660\n",
            "\t>>> Val.    : Loss 1.2316, Reg 0.0010, Acc 0.6628, precision: 0.6628, recall0.6628\n",
            "Saved model with highest acc ...\n",
            "Epoch 4: Best val loss 1.1994, Best val acc 0.6628, best val recall 0.6628, best val precision 0.6628\n",
            "\t>>> Training: Loss 1.1506, Reg 0.000, Acc 0.6661, precision: 0.6661, recall0.6661\n",
            "\t>>> Val.    : Loss 1.2369, Reg 0.0033, Acc 0.6625, precision: 0.6625, recall0.6625\n",
            "Epoch 5: Best val loss 1.1994, Best val acc 0.6628, best val recall 0.6628, best val precision 0.6628\n",
            "\t>>> Training: Loss 1.1492, Reg 0.000, Acc 0.6662, precision: 0.6662, recall0.6662\n",
            "\t>>> Val.    : Loss 1.2396, Reg 0.0030, Acc 0.6626, precision: 0.6626, recall0.6626\n",
            "Epoch 6: Best val loss 1.1994, Best val acc 0.6628, best val recall 0.6628, best val precision 0.6628\n",
            "\t>>> Training: Loss 1.1477, Reg 0.000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "\t>>> Val.    : Loss 1.2413, Reg 0.0028, Acc 0.6629, precision: 0.6629, recall0.6629\n",
            "Saved model with highest acc ...\n",
            "Epoch 7: Best val loss 1.1994, Best val acc 0.6629, best val recall 0.6629, best val precision 0.6629\n",
            "\t>>> Training: Loss 1.1464, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2437, Reg 0.0030, Acc 0.6631, precision: 0.6631, recall0.6631\n",
            "Saved model with highest acc ...\n",
            "Epoch 8: Best val loss 1.1994, Best val acc 0.6631, best val recall 0.6631, best val precision 0.6631\n",
            "\t>>> Training: Loss 1.1455, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2425, Reg 0.0028, Acc 0.6630, precision: 0.6630, recall0.6630\n",
            "Epoch 9: Best val loss 1.1994, Best val acc 0.6631, best val recall 0.6631, best val precision 0.6631\n",
            "\t>>> Training: Loss 1.1447, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2410, Reg 0.0027, Acc 0.6631, precision: 0.6631, recall0.6631\n",
            "Saved model with highest acc ...\n",
            "Epoch 10: Best val loss 1.1994, Best val acc 0.6631, best val recall 0.6631, best val precision 0.6631\n",
            "\t>>> Training: Loss 1.1438, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2424, Reg 0.0034, Acc 0.6630, precision: 0.6630, recall0.6630\n",
            "Epoch 11: Best val loss 1.1994, Best val acc 0.6631, best val recall 0.6631, best val precision 0.6631\n",
            "\t>>> Training: Loss 1.1428, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2439, Reg 0.0051, Acc 0.6631, precision: 0.6631, recall0.6631\n",
            "Epoch 12: Best val loss 1.1994, Best val acc 0.6631, best val recall 0.6631, best val precision 0.6631\n",
            "\t>>> Training: Loss 1.1420, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2440, Reg 0.0080, Acc 0.6632, precision: 0.6632, recall0.6632\n",
            "Saved model with highest acc ...\n",
            "Epoch 13: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1411, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2453, Reg 0.0134, Acc 0.6632, precision: 0.6632, recall0.6632\n",
            "Saved model with highest acc ...\n",
            "Epoch 14: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1400, Reg 0.000, Acc 0.6666, precision: 0.6666, recall0.6666\n",
            "\t>>> Val.    : Loss 1.2462, Reg 0.0176, Acc 0.6630, precision: 0.6630, recall0.6630\n",
            "Epoch 15: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1386, Reg 0.000, Acc 0.6666, precision: 0.6666, recall0.6666\n",
            "\t>>> Val.    : Loss 1.2478, Reg 0.0321, Acc 0.6631, precision: 0.6631, recall0.6631\n",
            "Epoch 16: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1368, Reg 0.000, Acc 0.6667, precision: 0.6667, recall0.6667\n",
            "\t>>> Val.    : Loss 1.2501, Reg 0.0624, Acc 0.6631, precision: 0.6631, recall0.6631\n",
            "Epoch 17: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1345, Reg 0.000, Acc 0.6669, precision: 0.6669, recall0.6669\n",
            "\t>>> Val.    : Loss 1.2524, Reg 0.1235, Acc 0.6631, precision: 0.6631, recall0.6631\n",
            "Epoch 18: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1316, Reg 0.000, Acc 0.6672, precision: 0.6672, recall0.6672\n",
            "\t>>> Val.    : Loss 1.2581, Reg 0.2187, Acc 0.6629, precision: 0.6629, recall0.6629\n",
            "Epoch 19: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1278, Reg 0.000, Acc 0.6676, precision: 0.6676, recall0.6676\n",
            "\t>>> Val.    : Loss 1.2683, Reg 0.3694, Acc 0.6626, precision: 0.6626, recall0.6626\n",
            "Epoch 20: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1230, Reg 0.000, Acc 0.6683, precision: 0.6683, recall0.6683\n",
            "\t>>> Val.    : Loss 1.2791, Reg 0.5750, Acc 0.6621, precision: 0.6621, recall0.6621\n",
            "Epoch 21: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1171, Reg 0.000, Acc 0.6694, precision: 0.6694, recall0.6694\n",
            "\t>>> Val.    : Loss 1.2941, Reg 0.8768, Acc 0.6617, precision: 0.6617, recall0.6617\n",
            "Epoch 22: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1101, Reg 0.000, Acc 0.6707, precision: 0.6707, recall0.6707\n",
            "\t>>> Val.    : Loss 1.3130, Reg 1.2589, Acc 0.6608, precision: 0.6608, recall0.6608\n",
            "Epoch 23: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.1022, Reg 0.000, Acc 0.6724, precision: 0.6724, recall0.6724\n",
            "\t>>> Val.    : Loss 1.3346, Reg 1.6333, Acc 0.6599, precision: 0.6599, recall0.6599\n",
            "Epoch 24: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.0939, Reg 0.000, Acc 0.6742, precision: 0.6742, recall0.6742\n",
            "\t>>> Val.    : Loss 1.3606, Reg 2.1378, Acc 0.6590, precision: 0.6590, recall0.6590\n",
            "Epoch 25: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.0845, Reg 0.000, Acc 0.6762, precision: 0.6762, recall0.6762\n",
            "\t>>> Val.    : Loss 1.3836, Reg 2.6965, Acc 0.6577, precision: 0.6577, recall0.6577\n",
            "Epoch 26: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.0747, Reg 0.000, Acc 0.6783, precision: 0.6783, recall0.6783\n",
            "\t>>> Val.    : Loss 1.4176, Reg 3.3895, Acc 0.6564, precision: 0.6564, recall0.6564\n",
            "Epoch 27: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.0651, Reg 0.000, Acc 0.6803, precision: 0.6803, recall0.6803\n",
            "\t>>> Val.    : Loss 1.4534, Reg 4.2154, Acc 0.6549, precision: 0.6549, recall0.6549\n",
            "Epoch 28: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.0553, Reg 0.000, Acc 0.6827, precision: 0.6827, recall0.6827\n",
            "\t>>> Val.    : Loss 1.4966, Reg 4.9506, Acc 0.6540, precision: 0.6540, recall0.6540\n",
            "Epoch 29: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.0455, Reg 0.000, Acc 0.6850, precision: 0.6850, recall0.6850\n",
            "\t>>> Val.    : Loss 1.5552, Reg 5.9186, Acc 0.6527, precision: 0.6527, recall0.6527\n",
            "Epoch 30: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.0358, Reg 0.000, Acc 0.6874, precision: 0.6874, recall0.6874\n",
            "\t>>> Val.    : Loss 1.6118, Reg 6.9356, Acc 0.6514, precision: 0.6514, recall0.6514\n",
            "Epoch 31: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.0263, Reg 0.000, Acc 0.6898, precision: 0.6898, recall0.6898\n",
            "\t>>> Val.    : Loss 1.6708, Reg 8.1986, Acc 0.6504, precision: 0.6504, recall0.6504\n",
            "Epoch 32: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.0161, Reg 0.000, Acc 0.6924, precision: 0.6924, recall0.6924\n",
            "\t>>> Val.    : Loss 1.7337, Reg 9.4709, Acc 0.6495, precision: 0.6495, recall0.6495\n",
            "Epoch 33: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 1.0061, Reg 0.000, Acc 0.6950, precision: 0.6950, recall0.6950\n",
            "\t>>> Val.    : Loss 1.7946, Reg 10.6977, Acc 0.6487, precision: 0.6487, recall0.6487\n",
            "Epoch 34: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.9955, Reg 0.000, Acc 0.6978, precision: 0.6978, recall0.6978\n",
            "\t>>> Val.    : Loss 1.8649, Reg 12.3082, Acc 0.6481, precision: 0.6481, recall0.6481\n",
            "Epoch 35: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.9847, Reg 0.000, Acc 0.7006, precision: 0.7006, recall0.7006\n",
            "\t>>> Val.    : Loss 1.9281, Reg 13.5945, Acc 0.6475, precision: 0.6475, recall0.6475\n",
            "Epoch 36: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.9741, Reg 0.000, Acc 0.7035, precision: 0.7035, recall0.7035\n",
            "\t>>> Val.    : Loss 2.0022, Reg 14.9115, Acc 0.6464, precision: 0.6464, recall0.6464\n",
            "Epoch 37: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.9640, Reg 0.000, Acc 0.7062, precision: 0.7062, recall0.7062\n",
            "\t>>> Val.    : Loss 2.0725, Reg 16.5400, Acc 0.6453, precision: 0.6453, recall0.6453\n",
            "Epoch 38: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.9543, Reg 0.000, Acc 0.7088, precision: 0.7088, recall0.7088\n",
            "\t>>> Val.    : Loss 2.1389, Reg 18.0167, Acc 0.6446, precision: 0.6446, recall0.6446\n",
            "Epoch 39: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.9443, Reg 0.000, Acc 0.7116, precision: 0.7116, recall0.7116\n",
            "\t>>> Val.    : Loss 2.1959, Reg 19.3628, Acc 0.6438, precision: 0.6438, recall0.6438\n",
            "Epoch 40: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.9347, Reg 0.000, Acc 0.7142, precision: 0.7142, recall0.7142\n",
            "\t>>> Val.    : Loss 2.2575, Reg 20.8032, Acc 0.6429, precision: 0.6429, recall0.6429\n",
            "Epoch 41: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.9248, Reg 0.000, Acc 0.7170, precision: 0.7170, recall0.7170\n",
            "\t>>> Val.    : Loss 2.3121, Reg 22.0654, Acc 0.6421, precision: 0.6421, recall0.6421\n",
            "Epoch 42: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.9153, Reg 0.000, Acc 0.7197, precision: 0.7197, recall0.7197\n",
            "\t>>> Val.    : Loss 2.3711, Reg 23.1525, Acc 0.6416, precision: 0.6416, recall0.6416\n",
            "Epoch 43: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.9058, Reg 0.000, Acc 0.7225, precision: 0.7225, recall0.7225\n",
            "\t>>> Val.    : Loss 2.4168, Reg 23.9117, Acc 0.6411, precision: 0.6411, recall0.6411\n",
            "Epoch 44: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8967, Reg 0.000, Acc 0.7251, precision: 0.7251, recall0.7251\n",
            "\t>>> Val.    : Loss 2.4540, Reg 24.4192, Acc 0.6405, precision: 0.6405, recall0.6405\n",
            "Epoch 45: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8877, Reg 0.000, Acc 0.7276, precision: 0.7276, recall0.7276\n",
            "\t>>> Val.    : Loss 2.4944, Reg 24.9392, Acc 0.6395, precision: 0.6395, recall0.6395\n",
            "Epoch 46: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8787, Reg 0.000, Acc 0.7302, precision: 0.7302, recall0.7302\n",
            "\t>>> Val.    : Loss 2.5358, Reg 25.2595, Acc 0.6391, precision: 0.6391, recall0.6391\n",
            "Epoch 47: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8697, Reg 0.000, Acc 0.7328, precision: 0.7328, recall0.7328\n",
            "\t>>> Val.    : Loss 2.5723, Reg 25.4918, Acc 0.6385, precision: 0.6385, recall0.6385\n",
            "Epoch 48: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8607, Reg 0.000, Acc 0.7354, precision: 0.7354, recall0.7354\n",
            "\t>>> Val.    : Loss 2.6109, Reg 25.7203, Acc 0.6381, precision: 0.6381, recall0.6381\n",
            "Epoch 49: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8521, Reg 0.000, Acc 0.7378, precision: 0.7378, recall0.7378\n",
            "\t>>> Val.    : Loss 2.6521, Reg 26.0220, Acc 0.6374, precision: 0.6374, recall0.6374\n",
            "Epoch 50: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8438, Reg 0.000, Acc 0.7403, precision: 0.7403, recall0.7403\n",
            "\t>>> Val.    : Loss 2.6977, Reg 26.2901, Acc 0.6370, precision: 0.6370, recall0.6370\n",
            "Epoch 51: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8354, Reg 0.000, Acc 0.7428, precision: 0.7428, recall0.7428\n",
            "\t>>> Val.    : Loss 2.7431, Reg 26.5442, Acc 0.6364, precision: 0.6364, recall0.6364\n",
            "Epoch 52: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8271, Reg 0.000, Acc 0.7452, precision: 0.7452, recall0.7452\n",
            "\t>>> Val.    : Loss 2.7904, Reg 26.8228, Acc 0.6357, precision: 0.6357, recall0.6357\n",
            "Epoch 53: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8188, Reg 0.000, Acc 0.7477, precision: 0.7477, recall0.7477\n",
            "\t>>> Val.    : Loss 2.8414, Reg 27.1471, Acc 0.6349, precision: 0.6349, recall0.6349\n",
            "Epoch 54: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8107, Reg 0.000, Acc 0.7501, precision: 0.7501, recall0.7501\n",
            "\t>>> Val.    : Loss 2.8954, Reg 27.5806, Acc 0.6340, precision: 0.6340, recall0.6340\n",
            "Epoch 55: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.8028, Reg 0.000, Acc 0.7524, precision: 0.7524, recall0.7524\n",
            "\t>>> Val.    : Loss 2.9574, Reg 28.0679, Acc 0.6330, precision: 0.6330, recall0.6330\n",
            "Epoch 56: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7949, Reg 0.000, Acc 0.7547, precision: 0.7547, recall0.7547\n",
            "\t>>> Val.    : Loss 3.0222, Reg 28.5244, Acc 0.6326, precision: 0.6326, recall0.6326\n",
            "Epoch 57: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7873, Reg 0.000, Acc 0.7570, precision: 0.7570, recall0.7570\n",
            "\t>>> Val.    : Loss 3.0895, Reg 29.0501, Acc 0.6319, precision: 0.6319, recall0.6319\n",
            "Epoch 58: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7800, Reg 0.000, Acc 0.7592, precision: 0.7592, recall0.7592\n",
            "\t>>> Val.    : Loss 3.1581, Reg 29.5961, Acc 0.6314, precision: 0.6314, recall0.6314\n",
            "Epoch 59: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7726, Reg 0.000, Acc 0.7614, precision: 0.7614, recall0.7614\n",
            "\t>>> Val.    : Loss 3.2384, Reg 30.4511, Acc 0.6309, precision: 0.6309, recall0.6309\n",
            "Epoch 60: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7654, Reg 0.000, Acc 0.7636, precision: 0.7636, recall0.7636\n",
            "\t>>> Val.    : Loss 3.3101, Reg 31.0038, Acc 0.6303, precision: 0.6303, recall0.6303\n",
            "Epoch 61: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7585, Reg 0.000, Acc 0.7657, precision: 0.7657, recall0.7657\n",
            "\t>>> Val.    : Loss 3.3811, Reg 31.4086, Acc 0.6297, precision: 0.6297, recall0.6297\n",
            "Epoch 62: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7518, Reg 0.000, Acc 0.7677, precision: 0.7677, recall0.7677\n",
            "\t>>> Val.    : Loss 3.4704, Reg 32.2464, Acc 0.6295, precision: 0.6295, recall0.6295\n",
            "Epoch 63: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7449, Reg 0.000, Acc 0.7697, precision: 0.7697, recall0.7697\n",
            "\t>>> Val.    : Loss 3.5584, Reg 32.8423, Acc 0.6291, precision: 0.6291, recall0.6291\n",
            "Epoch 64: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7383, Reg 0.000, Acc 0.7717, precision: 0.7717, recall0.7717\n",
            "\t>>> Val.    : Loss 3.6423, Reg 33.5822, Acc 0.6290, precision: 0.6290, recall0.6290\n",
            "Epoch 65: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7318, Reg 0.000, Acc 0.7737, precision: 0.7737, recall0.7737\n",
            "\t>>> Val.    : Loss 3.7213, Reg 34.5145, Acc 0.6287, precision: 0.6287, recall0.6287\n",
            "Epoch 66: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7256, Reg 0.000, Acc 0.7755, precision: 0.7755, recall0.7755\n",
            "\t>>> Val.    : Loss 3.7962, Reg 35.4157, Acc 0.6280, precision: 0.6280, recall0.6280\n",
            "Epoch 67: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7198, Reg 0.000, Acc 0.7773, precision: 0.7773, recall0.7773\n",
            "\t>>> Val.    : Loss 3.8587, Reg 35.7835, Acc 0.6273, precision: 0.6273, recall0.6273\n",
            "Epoch 68: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7141, Reg 0.000, Acc 0.7790, precision: 0.7790, recall0.7790\n",
            "\t>>> Val.    : Loss 3.9212, Reg 36.2714, Acc 0.6267, precision: 0.6267, recall0.6267\n",
            "Epoch 69: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7083, Reg 0.000, Acc 0.7807, precision: 0.7807, recall0.7807\n",
            "\t>>> Val.    : Loss 3.9834, Reg 36.7917, Acc 0.6264, precision: 0.6264, recall0.6264\n",
            "Epoch 70: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.7024, Reg 0.000, Acc 0.7825, precision: 0.7825, recall0.7825\n",
            "\t>>> Val.    : Loss 4.0498, Reg 37.5400, Acc 0.6261, precision: 0.6261, recall0.6261\n",
            "Epoch 71: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6965, Reg 0.000, Acc 0.7842, precision: 0.7842, recall0.7842\n",
            "\t>>> Val.    : Loss 4.1110, Reg 37.9601, Acc 0.6252, precision: 0.6252, recall0.6252\n",
            "Epoch 72: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6909, Reg 0.000, Acc 0.7859, precision: 0.7859, recall0.7859\n",
            "\t>>> Val.    : Loss 4.1767, Reg 38.5142, Acc 0.6245, precision: 0.6245, recall0.6245\n",
            "Epoch 73: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6853, Reg 0.000, Acc 0.7876, precision: 0.7876, recall0.7876\n",
            "\t>>> Val.    : Loss 4.2335, Reg 38.8254, Acc 0.6238, precision: 0.6238, recall0.6238\n",
            "Epoch 74: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6800, Reg 0.000, Acc 0.7892, precision: 0.7892, recall0.7892\n",
            "\t>>> Val.    : Loss 4.2981, Reg 39.3338, Acc 0.6231, precision: 0.6231, recall0.6231\n",
            "Epoch 75: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6747, Reg 0.000, Acc 0.7908, precision: 0.7908, recall0.7908\n",
            "\t>>> Val.    : Loss 4.3555, Reg 39.7925, Acc 0.6227, precision: 0.6227, recall0.6227\n",
            "Epoch 76: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6695, Reg 0.000, Acc 0.7924, precision: 0.7924, recall0.7924\n",
            "\t>>> Val.    : Loss 4.4096, Reg 40.1907, Acc 0.6221, precision: 0.6221, recall0.6221\n",
            "Epoch 77: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6644, Reg 0.000, Acc 0.7939, precision: 0.7939, recall0.7939\n",
            "\t>>> Val.    : Loss 4.4631, Reg 40.5417, Acc 0.6217, precision: 0.6217, recall0.6217\n",
            "Epoch 78: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6594, Reg 0.000, Acc 0.7954, precision: 0.7954, recall0.7954\n",
            "\t>>> Val.    : Loss 4.5278, Reg 40.8858, Acc 0.6215, precision: 0.6215, recall0.6215\n",
            "Epoch 79: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6546, Reg 0.000, Acc 0.7969, precision: 0.7969, recall0.7969\n",
            "\t>>> Val.    : Loss 4.5800, Reg 41.2714, Acc 0.6211, precision: 0.6211, recall0.6211\n",
            "Epoch 80: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6500, Reg 0.000, Acc 0.7983, precision: 0.7983, recall0.7983\n",
            "\t>>> Val.    : Loss 4.6323, Reg 41.6543, Acc 0.6205, precision: 0.6205, recall0.6205\n",
            "Epoch 81: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6452, Reg 0.000, Acc 0.7997, precision: 0.7997, recall0.7997\n",
            "\t>>> Val.    : Loss 4.6742, Reg 41.9942, Acc 0.6199, precision: 0.6199, recall0.6199\n",
            "Epoch 82: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6405, Reg 0.000, Acc 0.8012, precision: 0.8012, recall0.8012\n",
            "\t>>> Val.    : Loss 4.7195, Reg 42.2459, Acc 0.6195, precision: 0.6195, recall0.6195\n",
            "Epoch 83: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6358, Reg 0.000, Acc 0.8026, precision: 0.8026, recall0.8026\n",
            "\t>>> Val.    : Loss 4.7677, Reg 42.5856, Acc 0.6191, precision: 0.6191, recall0.6191\n",
            "Epoch 84: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6315, Reg 0.000, Acc 0.8039, precision: 0.8039, recall0.8039\n",
            "\t>>> Val.    : Loss 4.8228, Reg 43.1598, Acc 0.6188, precision: 0.6188, recall0.6188\n",
            "Epoch 85: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6270, Reg 0.000, Acc 0.8053, precision: 0.8053, recall0.8053\n",
            "\t>>> Val.    : Loss 4.8741, Reg 43.4910, Acc 0.6185, precision: 0.6185, recall0.6185\n",
            "Epoch 86: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6227, Reg 0.000, Acc 0.8066, precision: 0.8066, recall0.8066\n",
            "\t>>> Val.    : Loss 4.9218, Reg 43.8486, Acc 0.6183, precision: 0.6183, recall0.6183\n",
            "Epoch 87: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6182, Reg 0.000, Acc 0.8079, precision: 0.8079, recall0.8079\n",
            "\t>>> Val.    : Loss 4.9755, Reg 44.1879, Acc 0.6181, precision: 0.6181, recall0.6181\n",
            "Epoch 88: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6139, Reg 0.000, Acc 0.8093, precision: 0.8093, recall0.8093\n",
            "\t>>> Val.    : Loss 5.0335, Reg 44.5171, Acc 0.6179, precision: 0.6179, recall0.6179\n",
            "Epoch 89: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6096, Reg 0.000, Acc 0.8105, precision: 0.8105, recall0.8105\n",
            "\t>>> Val.    : Loss 5.0826, Reg 44.7988, Acc 0.6177, precision: 0.6177, recall0.6177\n",
            "Epoch 90: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6054, Reg 0.000, Acc 0.8118, precision: 0.8118, recall0.8118\n",
            "\t>>> Val.    : Loss 5.1382, Reg 45.2397, Acc 0.6174, precision: 0.6174, recall0.6174\n",
            "Epoch 91: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.6013, Reg 0.000, Acc 0.8130, precision: 0.8130, recall0.8130\n",
            "\t>>> Val.    : Loss 5.1873, Reg 45.7314, Acc 0.6171, precision: 0.6171, recall0.6171\n",
            "Epoch 92: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.5971, Reg 0.000, Acc 0.8143, precision: 0.8143, recall0.8143\n",
            "\t>>> Val.    : Loss 5.2365, Reg 46.1753, Acc 0.6170, precision: 0.6170, recall0.6170\n",
            "Epoch 93: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.5931, Reg 0.000, Acc 0.8155, precision: 0.8155, recall0.8155\n",
            "\t>>> Val.    : Loss 5.2957, Reg 46.5598, Acc 0.6167, precision: 0.6167, recall0.6167\n",
            "Epoch 94: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.5893, Reg 0.000, Acc 0.8167, precision: 0.8167, recall0.8167\n",
            "\t>>> Val.    : Loss 5.3560, Reg 47.0890, Acc 0.6165, precision: 0.6165, recall0.6165\n",
            "Epoch 95: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.5853, Reg 0.000, Acc 0.8179, precision: 0.8179, recall0.8179\n",
            "\t>>> Val.    : Loss 5.4183, Reg 47.5024, Acc 0.6162, precision: 0.6162, recall0.6162\n",
            "Epoch 96: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.5815, Reg 0.000, Acc 0.8191, precision: 0.8191, recall0.8191\n",
            "\t>>> Val.    : Loss 5.4716, Reg 47.9701, Acc 0.6160, precision: 0.6160, recall0.6160\n",
            "Epoch 97: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.5776, Reg 0.000, Acc 0.8203, precision: 0.8203, recall0.8203\n",
            "\t>>> Val.    : Loss 5.5282, Reg 48.5400, Acc 0.6158, precision: 0.6158, recall0.6158\n",
            "Epoch 98: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.5740, Reg 0.000, Acc 0.8215, precision: 0.8215, recall0.8215\n",
            "\t>>> Val.    : Loss 5.5764, Reg 48.9868, Acc 0.6155, precision: 0.6155, recall0.6155\n",
            "Epoch 99: Best val loss 1.1994, Best val acc 0.6632, best val recall 0.6632, best val precision 0.6632\n",
            "\t>>> Training: Loss 0.5702, Reg 0.000, Acc 0.8226, precision: 0.8226, recall0.8226\n",
            "\t>>> Val.    : Loss 5.6296, Reg 49.4003, Acc 0.6151, precision: 0.6151, recall0.6151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%mkdir /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints"
      ],
      "metadata": {
        "id": "O4m8fvzN-oJN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UULfzcFrynFz",
        "outputId": "86b1fd84-adeb-4112-95e4-8d75075b9465"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cp ./saved/model/epoch97_acc_0.762.ckpt /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints/CIRCLE/mobilenetv3l/"
      ],
      "metadata": {
        "id": "1hFw2rQB-7np"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}