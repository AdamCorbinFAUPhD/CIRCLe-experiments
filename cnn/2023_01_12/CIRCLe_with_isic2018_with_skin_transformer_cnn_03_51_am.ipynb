{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_HSnGPDTmtQqL19RJaSZ9opYOjST_pFh",
      "authorship_tag": "ABX9TyOy2VArG5XQhrSj56Ne68+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamCorbinFAUPhD/CIRCLe-experiments/blob/main/cnn/2023_01_12/CIRCLe_with_isic2018_with_skin_transformer_cnn_03_51_am.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment notes\n",
        "\n",
        "- date: 2023/01/11 8:26am\n",
        "- base model: simple cnn \n",
        "- Trying to add and test simple CNN\n",
        "- 8 hidden layer\n",
        "- .4 drop out\n",
        "\n",
        "Results: \n",
        "- no more overftting but stoped learning around 66% \n"
      ],
      "metadata": {
        "id": "5K9KcPXtTmUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "This notebook is used to modify the implementation of CIRCLe from this paper : [CIRCLe: Color Invariant Representation\n",
        "Learning for Unbiased Classification of Skin\n",
        "Lesions](https://arxiv.org/pdf/2208.13528.pdf)\n",
        "\n",
        "Their github repo is : https://github.com/arezou-pakzad/CIRCLe\n",
        "\n",
        "This paper uses the Fitzpatrick17k dataset which can be obtained here: https://github.com/mattgroh/fitzpatrick17k\n",
        "\n",
        "For these set of experiments we will use the ISIC 2017 dataset from: https://github.com/manideep2510/melanoma_segmentation.git "
      ],
      "metadata": {
        "id": "jCpy2CqVJ-VI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO list\n",
        "\n",
        "1. [X] Download 2018 dataset\n",
        "1. [X] Analize dataset to get Fitzpatrick info. \n",
        "1. [X] Save off Fitzpatrick info data so we dont have to do it every time\n",
        "1. [X] load cached fitzpatrick data\n",
        "1. [X] Create masks uing https://github.com/DebeshJha/2020-CBMS-DoubleU-Net Because Task 3 for 2018 doesnt havent masks. Trick was to get the higher end GPU and ram (12/29/2022)\n",
        "1. [X] Create pytorch dataloader for ISIC 2018 dataset including loading masks, images, diagnossis, fitzpatrick type for training (12/30/2022) needed to create custom split function\n",
        "1. [X] Create dataloaders for test and validation  (12/30/2022)\n",
        "1. [X] Added jupiter notebook download code into the github repo (1/1/2023)\n",
        "1. [X] plug in dataloader into CIRCLe main file (1/1/2023)\n",
        "1. [X] Figure out how to transform image and mask the same from the dataloader (1/2/2023)\n",
        "1. [X] Use the new dataloader to train the model (1/2/2023)\n",
        "1. [X] Use new transformer for CIRCLe model (1/3/2023)\n",
        "1. [ ] test using different base models\n",
        "1. [ ] test that adding dropout might help with overfitting\n",
        "1. [X] Add more metrics such as precision and recall (1/4/2023)\n",
        "1. [ ] add fairness metrics\n",
        "1. [ ] add confusion matrics\n",
        "1. [ ] add sensitivity and specificity\n",
        "1. [ ] add metrics for each class\n",
        "1. [ ] (optional) Go back and download and use larger datasets\n",
        "1. [ ] (optional) Run Fitzpatrick on larger datasets(currently using the test set from isic 2018 task 3)\n",
        "1. [ ] The dataloaders need to be split stratified different than the current \"training, validation, and test\" as given from https://challenge.isic-archive.com/data/#2018 based on skin types. 12/30/2022 - I think this is done BUT we might consider doing k-fold approach which adds another layer of complexity to the dataloaders"
      ],
      "metadata": {
        "id": "ajchIOEXMH4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the environment"
      ],
      "metadata": {
        "id": "1IqTnocWPMkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX3pAmwlWnf5",
        "outputId": "269866bb-75b2-4996-93d5-2109422464d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs & imports"
      ],
      "metadata": {
        "id": "yzsWv7g9MB87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download latest code"
      ],
      "metadata": {
        "id": "cLWa0BAdPQBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kQ5LposJzeZ",
        "outputId": "4168cd3e-56bc-4a1e-c9ee-a10d769a857b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CIRCLe'...\n",
            "remote: Enumerating objects: 481, done.\u001b[K\n",
            "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 481 (delta 79), reused 108 (delta 49), pack-reused 339\u001b[K\n",
            "Receiving objects: 100% (481/481), 1.81 MiB | 25.73 MiB/s, done.\n",
            "Resolving deltas: 100% (245/245), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/acorbin3/CIRCLe.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./CIRCLe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9eGp7LOm90J",
        "outputId": "40a0077b-eae4-4125-f764-e985f75470b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CIRCLe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- models/circle.py"
      ],
      "metadata": {
        "id": "OgCG317Q6qru"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNNuLRyKQ7-",
        "outputId": "5cb5fcd1-dd75-4063-9b4e-30aa02f3020b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r ./requirements.txt"
      ],
      "metadata": {
        "id": "DWzYtBAIKvuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212cb7fd-0aaf-4ac5-e06b-9fc4319ce058"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23.2\n",
            "  Downloading numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.4.4\n",
            "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.2.0\n",
            "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==1.1.2\n",
            "  Downloading scikit_learn-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow==2.9.2 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 5)) (2.9.2)\n",
            "Collecting torch==1.12.1\n",
            "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.1\n",
            "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 8)) (4.64.1)\n",
            "Collecting derm-ita>=0.0.8\n",
            "  Downloading derm_ita-0.0.8-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.1)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.19.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (21.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.51.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.29.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (14.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.25.1)\n",
            "Collecting patchify>=0.2.3\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Collecting scikit-image>=0.19\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.38.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2022.10.10)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.0.9)\n",
            "Collecting scipy>=1.3.2\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (5.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.2.2)\n",
            "Installing collected packages: torch, Pillow, numpy, torchvision, scipy, patchify, pandas, scikit_learn, scikit-image, derm-ita\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.2.0 derm-ita-0.0.8 numpy-1.23.2 pandas-1.4.4 patchify-0.2.3 scikit-image-0.19.3 scikit_learn-1.1.2 scipy-1.10.0 torch-1.12.1 torchvision-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This next block of code will be needed if you get this error: **\n",
        "\n",
        "A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation. The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70."
      ],
      "metadata": {
        "id": "1q3ovxukTHlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "qhckJLuHSlkS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IF ERROR, RESTART RUNTIME due to derm-ita lib\n",
        "This is due to derm-ita using newer libaries than the Google Colab default(during this time of 12/24/2022)"
      ],
      "metadata": {
        "id": "pB8smeonMesX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train CIRCLe model "
      ],
      "metadata": {
        "id": "fKUV22LhVzBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir ./saved\n",
        "%mkdir ./saved/model"
      ],
      "metadata": {
        "id": "08ngcZp9m1-S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- main.py\n",
        "!git checkout -- organize_data/isic_2018/dataset.py"
      ],
      "metadata": {
        "id": "y8uJMyX54Qti"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akY1e2Sh-FdU",
        "outputId": "8fcde812-0c0c-4f8e-d94e-864378652f04"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --use_reg_loss False --model cnn --dataset isic2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH5FKsbclkje",
        "outputId": "727caf8a-318b-4bc6-80f0-d40215317ae5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flags:\n",
            "\talpha: 0.1\n",
            "\tbase: vgg16\n",
            "\tbatch_size: 32\n",
            "\tdata_dir: ../data/fitz17k/images/all/\n",
            "\tdataset: isic2018\n",
            "\tepochs: 100\n",
            "\tgan_path: saved/stargan/\n",
            "\thidden_dim: 256\n",
            "\tlr: 0.001\n",
            "\tmodel: cnn\n",
            "\tmodel_save_dir: saved/model/\n",
            "\tnum_classes: 7\n",
            "\tseed: 1\n",
            "\tuse_reg_loss: True\n",
            "\tweight_decay: 0.001\n",
            "Downloading isic2018 images\n",
            "tcmalloc: large alloc 2771738624 bytes == 0xced58000 @  0x7fde1268d1e7 0x4d30a0 0x5dede2 0x6758aa 0x4f750a 0x4997a2 0x4f700d 0x4d4aa9 0x55e029 0x55cd91 0x5d8941 0x4fe318 0x5d8416 0x55f797 0x55cd91 0x5d8941 0x4fe318 0x5d8416 0x55f797 0x55cd91 0x5d8941 0x5d8416 0x55f797 0x55cd91 0x5d8941 0x4997c7 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4990ca\n",
            "Downloading isic2018 images. Complete!\n",
            "Downloading isic2018 masks\n",
            "Downloading isic2018 masks. Complete!\n",
            "Resizing masks\n",
            "Resizing masks. Complete!\n",
            "Donloading isic 2018 ground truth classification data\n",
            "Downloading transformed iaages\n",
            "Creating dataframe\n",
            "\t Looking for cached dataframe\n",
            "\t\t organize_data/isic_2018/saved_data_2022_12_27_isic_2018.csv\n",
            "Creating dataframe. Complete!\n",
            "Splitting up the dataset into train,test, validation datasets\n",
            "fizpatrick_skin_type: 1 8001\n",
            "\t train 6400\n",
            "\t test 800\n",
            "\t val 801\n",
            "fizpatrick_skin_type: 2 1049\n",
            "\t train 839\n",
            "\t test 105\n",
            "\t val 105\n",
            "fizpatrick_skin_type: 3 513\n",
            "\t train 410\n",
            "\t test 51\n",
            "\t val 52\n",
            "fizpatrick_skin_type: 4 182\n",
            "\t train 145\n",
            "\t test 18\n",
            "\t val 19\n",
            "fizpatrick_skin_type: 5 107\n",
            "\t train 85\n",
            "\t test 11\n",
            "\t val 11\n",
            "fizpatrick_skin_type: 6 163\n",
            "\t train 130\n",
            "\t test 16\n",
            "\t val 17\n",
            "total_train: 8009 79.9700449326011\n",
            "total_test: 1001 9.995007488766849\n",
            "total_val: 1005 10.034947578632051\n",
            "train size: 8009\n",
            "test size: 1001\n",
            "val size: 1005\n",
            "\ttrain: skin type 1 : 6400\n",
            "\ttrain: skin type 2 : 839\n",
            "\ttrain: skin type 3 : 410\n",
            "\ttrain: skin type 4 : 145\n",
            "\ttrain: skin type 5 : 85\n",
            "\ttrain: skin type 6 : 130\n",
            "----\n",
            "\ttest: skin type 1 : 800\n",
            "\ttest: skin type 2 : 105\n",
            "\ttest: skin type 3 : 51\n",
            "\ttest: skin type 4 : 18\n",
            "\ttest: skin type 5 : 11\n",
            "\ttest: skin type 6 : 16\n",
            "----\n",
            "\tval: skin type 1 : 801\n",
            "\tval: skin type 2 : 105\n",
            "\tval: skin type 3 : 52\n",
            "\tval: skin type 4 : 19\n",
            "\tval: skin type 5 : 11\n",
            "\tval: skin type 6 : 17\n",
            "train size: 8009\n",
            "val size: 1005\n",
            "train skin types: [1 2 3 4 5 6]\n",
            "val skin types: [1 2 3 4 5 6]\n",
            "train skin conditions: 7\n",
            "val skin conditions: 7\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 128, 128]             448\n",
            "              ReLU-2         [-1, 16, 128, 128]               0\n",
            "         MaxPool2d-3           [-1, 16, 64, 64]               0\n",
            "            Conv2d-4           [-1, 32, 64, 64]           4,640\n",
            "              ReLU-5           [-1, 32, 64, 64]               0\n",
            "         MaxPool2d-6           [-1, 32, 32, 32]               0\n",
            "            Conv2d-7           [-1, 64, 32, 32]          18,496\n",
            "              ReLU-8           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-9           [-1, 64, 16, 16]               0\n",
            "          Flatten-10                [-1, 16384]               0\n",
            "           Linear-11                    [-1, 8]         131,080\n",
            "          Dropout-12                    [-1, 8]               0\n",
            "           Linear-13                    [-1, 7]              63\n",
            "================================================================\n",
            "Total params: 154,727\n",
            "Trainable params: 154,727\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 8.00\n",
            "Params size (MB): 0.59\n",
            "Estimated Total Size (MB): 8.78\n",
            "----------------------------------------------------------------\n",
            "Epoch 0: Best val loss inf, Best val acc 0.0000, best val recall 0.0000, best val precision 0.0000\n",
            "\t>>> Training: Loss 1.2569, Reg 0.000, Acc 0.6567, precision: 0.6567, recall0.6567\n",
            "\t>>> Val.    : Loss 1.2778, Reg 0.0005, Acc 0.6573, precision: 0.6573, recall0.6573\n",
            "Saved model with highest acc ...\n",
            "Epoch 1: Best val loss 1.2778, Best val acc 0.6573, best val recall 0.6573, best val precision 0.6573\n",
            "\t>>> Training: Loss 1.2211, Reg 0.000, Acc 0.6617, precision: 0.6617, recall0.6617\n",
            "\t>>> Val.    : Loss 1.3034, Reg 0.0004, Acc 0.6598, precision: 0.6598, recall0.6598\n",
            "Saved model with highest acc ...\n",
            "Epoch 2: Best val loss 1.2778, Best val acc 0.6598, best val recall 0.6598, best val precision 0.6598\n",
            "\t>>> Training: Loss 1.2036, Reg 0.000, Acc 0.6634, precision: 0.6634, recall0.6634\n",
            "\t>>> Val.    : Loss 1.2883, Reg 0.0003, Acc 0.6620, precision: 0.6620, recall0.6620\n",
            "Saved model with highest acc ...\n",
            "Epoch 3: Best val loss 1.2778, Best val acc 0.6620, best val recall 0.6620, best val precision 0.6620\n",
            "\t>>> Training: Loss 1.1926, Reg 0.000, Acc 0.6642, precision: 0.6642, recall0.6642\n",
            "\t>>> Val.    : Loss 1.2816, Reg 0.0002, Acc 0.6623, precision: 0.6623, recall0.6623\n",
            "Saved model with highest acc ...\n",
            "Epoch 4: Best val loss 1.2778, Best val acc 0.6623, best val recall 0.6623, best val precision 0.6623\n",
            "\t>>> Training: Loss 1.1848, Reg 0.000, Acc 0.6647, precision: 0.6647, recall0.6647\n",
            "\t>>> Val.    : Loss 1.2808, Reg 0.0002, Acc 0.6625, precision: 0.6625, recall0.6625\n",
            "Saved model with highest acc ...\n",
            "Epoch 5: Best val loss 1.2778, Best val acc 0.6625, best val recall 0.6625, best val precision 0.6625\n",
            "\t>>> Training: Loss 1.1795, Reg 0.000, Acc 0.6651, precision: 0.6651, recall0.6651\n",
            "\t>>> Val.    : Loss 1.2787, Reg 0.0002, Acc 0.6631, precision: 0.6631, recall0.6631\n",
            "Saved model with highest acc ...\n",
            "Epoch 6: Best val loss 1.2778, Best val acc 0.6631, best val recall 0.6631, best val precision 0.6631\n",
            "\t>>> Training: Loss 1.1751, Reg 0.000, Acc 0.6653, precision: 0.6653, recall0.6653\n",
            "\t>>> Val.    : Loss 1.2763, Reg 0.0001, Acc 0.6633, precision: 0.6633, recall0.6633\n",
            "Saved model with highest acc ...\n",
            "Epoch 7: Best val loss 1.2763, Best val acc 0.6633, best val recall 0.6633, best val precision 0.6633\n",
            "\t>>> Training: Loss 1.1713, Reg 0.000, Acc 0.6655, precision: 0.6655, recall0.6655\n",
            "\t>>> Val.    : Loss 1.2758, Reg 0.0003, Acc 0.6633, precision: 0.6633, recall0.6633\n",
            "Epoch 8: Best val loss 1.2758, Best val acc 0.6633, best val recall 0.6633, best val precision 0.6633\n",
            "\t>>> Training: Loss 1.1683, Reg 0.000, Acc 0.6656, precision: 0.6656, recall0.6656\n",
            "\t>>> Val.    : Loss 1.2736, Reg 0.0002, Acc 0.6634, precision: 0.6634, recall0.6634\n",
            "Saved model with highest acc ...\n",
            "Epoch 9: Best val loss 1.2736, Best val acc 0.6634, best val recall 0.6634, best val precision 0.6634\n",
            "\t>>> Training: Loss 1.1657, Reg 0.000, Acc 0.6657, precision: 0.6657, recall0.6657\n",
            "\t>>> Val.    : Loss 1.2707, Reg 0.0002, Acc 0.6636, precision: 0.6636, recall0.6636\n",
            "Saved model with highest acc ...\n",
            "Epoch 10: Best val loss 1.2707, Best val acc 0.6636, best val recall 0.6636, best val precision 0.6636\n",
            "\t>>> Training: Loss 1.1633, Reg 0.000, Acc 0.6658, precision: 0.6658, recall0.6658\n",
            "\t>>> Val.    : Loss 1.2740, Reg 0.0002, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Saved model with highest acc ...\n",
            "Epoch 11: Best val loss 1.2707, Best val acc 0.6638, best val recall 0.6638, best val precision 0.6638\n",
            "\t>>> Training: Loss 1.1615, Reg 0.000, Acc 0.6659, precision: 0.6659, recall0.6659\n",
            "\t>>> Val.    : Loss 1.2764, Reg 0.0002, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 12: Best val loss 1.2707, Best val acc 0.6638, best val recall 0.6638, best val precision 0.6638\n",
            "\t>>> Training: Loss 1.1596, Reg 0.000, Acc 0.6660, precision: 0.6660, recall0.6660\n",
            "\t>>> Val.    : Loss 1.2734, Reg 0.0005, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Saved model with highest acc ...\n",
            "Epoch 13: Best val loss 1.2707, Best val acc 0.6638, best val recall 0.6638, best val precision 0.6638\n",
            "\t>>> Training: Loss 1.1579, Reg 0.000, Acc 0.6660, precision: 0.6660, recall0.6660\n",
            "\t>>> Val.    : Loss 1.2743, Reg 0.0005, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 14: Best val loss 1.2707, Best val acc 0.6638, best val recall 0.6638, best val precision 0.6638\n",
            "\t>>> Training: Loss 1.1566, Reg 0.000, Acc 0.6661, precision: 0.6661, recall0.6661\n",
            "\t>>> Val.    : Loss 1.2764, Reg 0.0004, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 15: Best val loss 1.2707, Best val acc 0.6638, best val recall 0.6638, best val precision 0.6638\n",
            "\t>>> Training: Loss 1.1556, Reg 0.000, Acc 0.6661, precision: 0.6661, recall0.6661\n",
            "\t>>> Val.    : Loss 1.2759, Reg 0.0004, Acc 0.6639, precision: 0.6639, recall0.6639\n",
            "Saved model with highest acc ...\n",
            "Epoch 16: Best val loss 1.2707, Best val acc 0.6639, best val recall 0.6639, best val precision 0.6639\n",
            "\t>>> Training: Loss 1.1546, Reg 0.000, Acc 0.6662, precision: 0.6662, recall0.6662\n",
            "\t>>> Val.    : Loss 1.2761, Reg 0.0004, Acc 0.6640, precision: 0.6640, recall0.6640\n",
            "Saved model with highest acc ...\n",
            "Epoch 17: Best val loss 1.2707, Best val acc 0.6640, best val recall 0.6640, best val precision 0.6640\n",
            "\t>>> Training: Loss 1.1538, Reg 0.000, Acc 0.6662, precision: 0.6662, recall0.6662\n",
            "\t>>> Val.    : Loss 1.2751, Reg 0.0004, Acc 0.6640, precision: 0.6640, recall0.6640\n",
            "Saved model with highest acc ...\n",
            "Epoch 18: Best val loss 1.2707, Best val acc 0.6640, best val recall 0.6640, best val precision 0.6640\n",
            "\t>>> Training: Loss 1.1530, Reg 0.000, Acc 0.6662, precision: 0.6662, recall0.6662\n",
            "\t>>> Val.    : Loss 1.2754, Reg 0.0003, Acc 0.6640, precision: 0.6640, recall0.6640\n",
            "Epoch 19: Best val loss 1.2707, Best val acc 0.6640, best val recall 0.6640, best val precision 0.6640\n",
            "\t>>> Training: Loss 1.1524, Reg 0.000, Acc 0.6662, precision: 0.6662, recall0.6662\n",
            "\t>>> Val.    : Loss 1.2716, Reg 0.0005, Acc 0.6641, precision: 0.6641, recall0.6641\n",
            "Saved model with highest acc ...\n",
            "Epoch 20: Best val loss 1.2707, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1516, Reg 0.000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "\t>>> Val.    : Loss 1.2714, Reg 0.0005, Acc 0.6640, precision: 0.6640, recall0.6640\n",
            "Epoch 21: Best val loss 1.2707, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1511, Reg 0.000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "\t>>> Val.    : Loss 1.2685, Reg 0.0006, Acc 0.6640, precision: 0.6640, recall0.6640\n",
            "Epoch 22: Best val loss 1.2685, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1504, Reg 0.000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "\t>>> Val.    : Loss 1.2679, Reg 0.0006, Acc 0.6639, precision: 0.6639, recall0.6639\n",
            "Epoch 23: Best val loss 1.2679, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1499, Reg 0.000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "\t>>> Val.    : Loss 1.2672, Reg 0.0005, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 24: Best val loss 1.2672, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1494, Reg 0.000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "\t>>> Val.    : Loss 1.2659, Reg 0.0005, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 25: Best val loss 1.2659, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1491, Reg 0.000, Acc 0.6663, precision: 0.6663, recall0.6663\n",
            "\t>>> Val.    : Loss 1.2637, Reg 0.0005, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 26: Best val loss 1.2637, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1487, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2611, Reg 0.0005, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 27: Best val loss 1.2611, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1482, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2601, Reg 0.0005, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 28: Best val loss 1.2601, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1478, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2587, Reg 0.0005, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 29: Best val loss 1.2587, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1475, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2571, Reg 0.0004, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 30: Best val loss 1.2571, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1472, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2550, Reg 0.0004, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 31: Best val loss 1.2550, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1469, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2530, Reg 0.0004, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 32: Best val loss 1.2530, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1466, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2506, Reg 0.0004, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 33: Best val loss 1.2506, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1464, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2480, Reg 0.0004, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 34: Best val loss 1.2480, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1462, Reg 0.000, Acc 0.6664, precision: 0.6664, recall0.6664\n",
            "\t>>> Val.    : Loss 1.2454, Reg 0.0004, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 35: Best val loss 1.2454, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1459, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2427, Reg 0.0004, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 36: Best val loss 1.2427, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1457, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2401, Reg 0.0004, Acc 0.6639, precision: 0.6639, recall0.6639\n",
            "Epoch 37: Best val loss 1.2401, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1455, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2379, Reg 0.0003, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 38: Best val loss 1.2379, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1453, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2359, Reg 0.0003, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 39: Best val loss 1.2359, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1452, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2340, Reg 0.0003, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 40: Best val loss 1.2340, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1450, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2318, Reg 0.0003, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 41: Best val loss 1.2318, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1448, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2300, Reg 0.0003, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 42: Best val loss 1.2300, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1447, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2282, Reg 0.0003, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 43: Best val loss 1.2282, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1445, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2279, Reg 0.0003, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 44: Best val loss 1.2279, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1444, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2262, Reg 0.0003, Acc 0.6638, precision: 0.6638, recall0.6638\n",
            "Epoch 45: Best val loss 1.2262, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1442, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2247, Reg 0.0003, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 46: Best val loss 1.2247, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1440, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2254, Reg 0.0003, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 47: Best val loss 1.2247, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1438, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2238, Reg 0.0003, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 48: Best val loss 1.2238, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1437, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2222, Reg 0.0003, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 49: Best val loss 1.2222, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1435, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2208, Reg 0.0003, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 50: Best val loss 1.2208, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "\t>>> Training: Loss 1.1433, Reg 0.000, Acc 0.6665, precision: 0.6665, recall0.6665\n",
            "\t>>> Val.    : Loss 1.2201, Reg 0.0004, Acc 0.6637, precision: 0.6637, recall0.6637\n",
            "Epoch 51: Best val loss 1.2201, Best val acc 0.6641, best val recall 0.6641, best val precision 0.6641\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 119, in <module>\n",
            "    for x, y, transformed_image in tqdm(train_loader, ncols=75, leave=False):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tqdm/std.py\", line 1195, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 681, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1359, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1315, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1163, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.8/queue.py\", line 179, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 306, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%mkdir /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints"
      ],
      "metadata": {
        "id": "O4m8fvzN-oJN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UULfzcFrynFz",
        "outputId": "e2b1ebdd-0dff-4161-c765-cc4708cec0cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cp ./saved/model/epoch97_acc_0.762.ckpt /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints/CIRCLE/mobilenetv3l/"
      ],
      "metadata": {
        "id": "1hFw2rQB-7np"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}