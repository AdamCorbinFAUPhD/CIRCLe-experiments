{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1_HSnGPDTmtQqL19RJaSZ9opYOjST_pFh",
      "authorship_tag": "ABX9TyOc6kyfbPozlRR0+GmasqKe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamCorbinFAUPhD/CIRCLe-experiments/blob/main/densenet121/2023_01_05/CIRCLe_with_isic2018_with_skin_transformer_densenet121.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment notes\n",
        "- date: 2023/01/05 3:40am\n",
        "- base model: densenet212\n",
        "- moved optim.zero_grad() before the forwardpass.\n",
        "- Changing hidding dimention to 512\n",
        "\n",
        "\n",
        "Results: \n",
        "\n"
      ],
      "metadata": {
        "id": "7n3C7hssBDI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "This notebook is used to modify the implementation of CIRCLe from this paper : [CIRCLe: Color Invariant Representation\n",
        "Learning for Unbiased Classification of Skin\n",
        "Lesions](https://arxiv.org/pdf/2208.13528.pdf)\n",
        "\n",
        "Their github repo is : https://github.com/arezou-pakzad/CIRCLe\n",
        "\n",
        "This paper uses the Fitzpatrick17k dataset which can be obtained here: https://github.com/mattgroh/fitzpatrick17k\n",
        "\n",
        "For these set of experiments we will use the ISIC 2017 dataset from: https://github.com/manideep2510/melanoma_segmentation.git "
      ],
      "metadata": {
        "id": "jCpy2CqVJ-VI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO list\n",
        "\n",
        "1. [X] Download 2018 dataset\n",
        "1. [X] Analize dataset to get Fitzpatrick info. \n",
        "1. [X] Save off Fitzpatrick info data so we dont have to do it every time\n",
        "1. [X] load cached fitzpatrick data\n",
        "1. [X] Create masks uing https://github.com/DebeshJha/2020-CBMS-DoubleU-Net Because Task 3 for 2018 doesnt havent masks. Trick was to get the higher end GPU and ram (12/29/2022)\n",
        "1. [X] Create pytorch dataloader for ISIC 2018 dataset including loading masks, images, diagnossis, fitzpatrick type for training (12/30/2022) needed to create custom split function\n",
        "1. [X] Create dataloaders for test and validation  (12/30/2022)\n",
        "1. [X] Added jupiter notebook download code into the github repo (1/1/2023)\n",
        "1. [X] plug in dataloader into CIRCLe main file (1/1/2023)\n",
        "1. [X] Figure out how to transform image and mask the same from the dataloader (1/2/2023)\n",
        "1. [X] Use the new dataloader to train the model (1/2/2023)\n",
        "1. [X] Use new transformer for CIRCLe model (1/3/2023)\n",
        "1. [ ] test using different base models\n",
        "1. [ ] test that adding dropout might help with overfitting\n",
        "1. [ ] Add more metrics such as precision and recall\n",
        "1. [ ] add fairness metrics\n",
        "1. [ ] add confusion matrics\n",
        "1. [ ] add sensitivity and specificity\n",
        "1. [ ] add metrics for each class\n",
        "1. [ ] Turn back on the random rotation and flipping in the dataloader\n",
        "1. [ ] (optional) Go back and download and use larger datasets\n",
        "1. [ ] (optional) Run Fitzpatrick on larger datasets(currently using the test set from isic 2018 task 3)\n",
        "1. [ ] The dataloaders need to be split stratified different than the current \"training, validation, and test\" as given from https://challenge.isic-archive.com/data/#2018 based on skin types. 12/30/2022 - I think this is done BUT we might consider doing k-fold approach which adds another layer of complexity to the dataloaders"
      ],
      "metadata": {
        "id": "ajchIOEXMH4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the environment"
      ],
      "metadata": {
        "id": "1IqTnocWPMkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "DATASET_USED = \"ISIC_2018\"  # ISIC_2017_ORIG, ISIC_2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX3pAmwlWnf5",
        "outputId": "3a141da5-2a6d-4637-f54a-bf03f041ba81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs & imports"
      ],
      "metadata": {
        "id": "yzsWv7g9MB87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import torch\n",
        "\n",
        "from enum import Enum\n",
        "import io\n",
        "import math\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import skimage\n",
        "from skimage import color, util\n",
        "\n",
        "import PIL\n",
        "from PIL import ImageStat\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "\n",
        "import cv2\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import glob\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.metrics import *\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "ylyPAeA2lHbM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download latest code"
      ],
      "metadata": {
        "id": "cLWa0BAdPQBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kQ5LposJzeZ",
        "outputId": "8b5fb465-2dd2-4ab3-f444-9f701772e5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CIRCLe'...\n",
            "remote: Enumerating objects: 290, done.\u001b[K\n",
            "remote: Counting objects: 100% (290/290), done.\u001b[K\n",
            "remote: Compressing objects: 100% (195/195), done.\u001b[K\n",
            "remote: Total 290 (delta 140), reused 234 (delta 91), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (290/290), 1.78 MiB | 11.59 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/acorbin3/CIRCLe.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./CIRCLe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9eGp7LOm90J",
        "outputId": "09f8a22d-a53f-4b22-dae9-da73997f9f87"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CIRCLe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- models/circle.py"
      ],
      "metadata": {
        "id": "OgCG317Q6qru"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNNuLRyKQ7-",
        "outputId": "81c8dadc-7e71-4677-e783-f5b3ff46efc6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r ./requirements.txt"
      ],
      "metadata": {
        "id": "DWzYtBAIKvuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41dfa86-6b23-40ba-c04c-8107a59c8cee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23.2\n",
            "  Downloading numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.4.4\n",
            "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.2.0\n",
            "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==1.1.2\n",
            "  Downloading scikit_learn-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow==2.9.2 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 5)) (2.9.2)\n",
            "Collecting torch==1.12.1\n",
            "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.1\n",
            "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r ./requirements.txt (line 8)) (4.64.1)\n",
            "Collecting derm-ita>=0.0.8\n",
            "  Downloading derm_ita-0.0.8-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.4.4->-r ./requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.1.2->-r ./requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.29.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (21.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (14.0.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.51.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.19.6)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.25.1)\n",
            "Collecting scikit-image>=0.19\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting patchify>=0.2.3\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.38.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2022.10.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.19->derm-ita>=0.0.8->-r ./requirements.txt (line 9)) (2.8.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.0.9)\n",
            "Collecting scipy>=1.3.2\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1->-r ./requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->-r ./requirements.txt (line 5)) (3.2.2)\n",
            "Installing collected packages: torch, Pillow, numpy, torchvision, scipy, patchify, pandas, scikit_learn, scikit-image, derm-ita\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.2.0 derm-ita-0.0.8 numpy-1.23.2 pandas-1.4.4 patchify-0.2.3 scikit-image-0.19.3 scikit_learn-1.1.2 scipy-1.10.0 torch-1.12.1 torchvision-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IF ERROR, RESTART RUNTIME due to derm-ita lib\n",
        "This is due to derm-ita using newer libaries than the Google Colab default(during this time of 12/24/2022)"
      ],
      "metadata": {
        "id": "pB8smeonMesX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train CIRCLe model "
      ],
      "metadata": {
        "id": "fKUV22LhVzBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir ./saved\n",
        "%mkdir ./saved/model"
      ],
      "metadata": {
        "id": "08ngcZp9m1-S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- ./models/circle.py"
      ],
      "metadata": {
        "id": "IvF9sw289-yh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -- main.py"
      ],
      "metadata": {
        "id": "7sd5djCe4Atk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akY1e2Sh-FdU",
        "outputId": "4a4cd9c6-b1e9-493e-e837-c2be36c8be3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --use_reg_loss True --base densenet121 --dataset alexnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH5FKsbclkje",
        "outputId": "72e857f9-d40a-4b08-b31e-688706c8b1f7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flags:\n",
            "\talpha: 0.1\n",
            "\tbase: densenet121\n",
            "\tbatch_size: 32\n",
            "\tdata_dir: ../data/fitz17k/images/all/\n",
            "\tdataset: isic2018\n",
            "\tepochs: 100\n",
            "\tgan_path: saved/stargan/\n",
            "\thidden_dim: 128\n",
            "\tlr: 0.001\n",
            "\tmodel: circle\n",
            "\tmodel_save_dir: saved/model/\n",
            "\tnum_classes: 7\n",
            "\tseed: 1\n",
            "\tuse_reg_loss: True\n",
            "\tweight_decay: 0.001\n",
            "isic2018 images already downloaded\n",
            "isic 2018 masks already downladed\n",
            "Donloading isic 2018 ground truth classification data\n",
            "Creating dataframe\n",
            "\t Looking for cached dataframe\n",
            "\t\t organize_data/isic_2018/saved_data_2022_12_27_isic_2018.csv\n",
            "Creating dataframe. Complete!\n",
            "Splitting up the dataset into train,test, validation datasets\n",
            "fizpatrick_skin_type: 1 8001\n",
            "\t train 6400\n",
            "\t test 800\n",
            "\t val 801\n",
            "fizpatrick_skin_type: 2 1049\n",
            "\t train 839\n",
            "\t test 105\n",
            "\t val 105\n",
            "fizpatrick_skin_type: 3 513\n",
            "\t train 410\n",
            "\t test 51\n",
            "\t val 52\n",
            "fizpatrick_skin_type: 4 182\n",
            "\t train 145\n",
            "\t test 18\n",
            "\t val 19\n",
            "fizpatrick_skin_type: 5 107\n",
            "\t train 85\n",
            "\t test 11\n",
            "\t val 11\n",
            "fizpatrick_skin_type: 6 163\n",
            "\t train 130\n",
            "\t test 16\n",
            "\t val 17\n",
            "total_train: 8009 79.9700449326011\n",
            "total_test: 1001 9.995007488766849\n",
            "total_val: 1005 10.034947578632051\n",
            "train size: 8009\n",
            "test size: 1001\n",
            "val size: 1005\n",
            "\ttrain: skin type 1 : 6400\n",
            "\ttrain: skin type 2 : 839\n",
            "\ttrain: skin type 3 : 410\n",
            "\ttrain: skin type 4 : 145\n",
            "\ttrain: skin type 5 : 85\n",
            "\ttrain: skin type 6 : 130\n",
            "----\n",
            "\ttest: skin type 1 : 800\n",
            "\ttest: skin type 2 : 105\n",
            "\ttest: skin type 3 : 51\n",
            "\ttest: skin type 4 : 18\n",
            "\ttest: skin type 5 : 11\n",
            "\ttest: skin type 6 : 16\n",
            "----\n",
            "\tval: skin type 1 : 801\n",
            "\tval: skin type 2 : 105\n",
            "\tval: skin type 3 : 52\n",
            "\tval: skin type 4 : 19\n",
            "\tval: skin type 5 : 11\n",
            "\tval: skin type 6 : 17\n",
            "train size: 8009\n",
            "val size: 1005\n",
            "train skin types: [1 2 3 4 5 6]\n",
            "val skin types: [1 2 3 4 5 6]\n",
            "train skin conditions: 7\n",
            "val skin conditions: 7\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 0: Best val loss inf, Best val acc 0.0\n",
            ">>> Training: Loss 1.220, Reg 0.051, Acc 0.648, precision: 0.648, recall0.648\n",
            ">>> Val: Loss 1.241, Reg 0.000, Acc 0.663, precision: 0.663, recall0.663\n",
            "Saved model with highest acc ...\n",
            "Epoch 1: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 1.119, Reg 0.031, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.235, Reg 0.000, Acc 0.662, precision: 0.662, recall0.662\n",
            "Epoch 2: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 1.027, Reg 0.027, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.276, Reg 0.000, Acc 0.663, precision: 0.663, recall0.663\n",
            "Epoch 3: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.938, Reg 0.029, Acc 0.667, precision: 0.667, recall0.667\n",
            ">>> Val: Loss 1.412, Reg 0.000, Acc 0.661, precision: 0.661, recall0.661\n",
            "Epoch 4: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.918, Reg 0.030, Acc 0.670, precision: 0.670, recall0.670\n",
            ">>> Val: Loss 1.545, Reg 0.000, Acc 0.659, precision: 0.659, recall0.659\n",
            "Epoch 5: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.842, Reg 0.034, Acc 0.690, precision: 0.690, recall0.690\n",
            ">>> Val: Loss 1.553, Reg 0.000, Acc 0.639, precision: 0.639, recall0.639\n",
            "Epoch 6: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.775, Reg 0.037, Acc 0.715, precision: 0.715, recall0.715\n",
            ">>> Val: Loss 1.631, Reg 0.000, Acc 0.632, precision: 0.632, recall0.632\n",
            "Epoch 7: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.757, Reg 0.036, Acc 0.724, precision: 0.724, recall0.724\n",
            ">>> Val: Loss 1.723, Reg 0.000, Acc 0.619, precision: 0.619, recall0.619\n",
            "Epoch 8: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.698, Reg 0.038, Acc 0.743, precision: 0.743, recall0.743\n",
            ">>> Val: Loss 1.896, Reg 0.000, Acc 0.645, precision: 0.645, recall0.645\n",
            "Epoch 9: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.651, Reg 0.039, Acc 0.759, precision: 0.759, recall0.759\n",
            ">>> Val: Loss 1.791, Reg 0.000, Acc 0.611, precision: 0.611, recall0.611\n",
            "Epoch 10: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.597, Reg 0.039, Acc 0.777, precision: 0.777, recall0.777\n",
            ">>> Val: Loss 2.046, Reg 0.000, Acc 0.620, precision: 0.620, recall0.620\n",
            "Epoch 11: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.541, Reg 0.041, Acc 0.799, precision: 0.799, recall0.799\n",
            ">>> Val: Loss 2.099, Reg 0.000, Acc 0.610, precision: 0.610, recall0.610\n",
            "Epoch 12: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.475, Reg 0.043, Acc 0.828, precision: 0.828, recall0.828\n",
            ">>> Val: Loss 1.938, Reg 0.000, Acc 0.565, precision: 0.565, recall0.565\n",
            "Epoch 13: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.391, Reg 0.045, Acc 0.863, precision: 0.863, recall0.863\n",
            ">>> Val: Loss 2.110, Reg 0.000, Acc 0.603, precision: 0.603, recall0.603\n",
            "Epoch 14: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.313, Reg 0.047, Acc 0.892, precision: 0.892, recall0.892\n",
            ">>> Val: Loss 2.140, Reg 0.000, Acc 0.610, precision: 0.610, recall0.610\n",
            "Epoch 15: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.246, Reg 0.047, Acc 0.917, precision: 0.917, recall0.917\n",
            ">>> Val: Loss 2.299, Reg 0.000, Acc 0.610, precision: 0.610, recall0.610\n",
            "Epoch 16: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.197, Reg 0.047, Acc 0.935, precision: 0.935, recall0.935\n",
            ">>> Val: Loss 2.653, Reg 0.000, Acc 0.643, precision: 0.643, recall0.643\n",
            "Epoch 17: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.166, Reg 0.046, Acc 0.943, precision: 0.943, recall0.943\n",
            ">>> Val: Loss 2.761, Reg 0.000, Acc 0.641, precision: 0.641, recall0.641\n",
            "Epoch 18: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.136, Reg 0.044, Acc 0.959, precision: 0.959, recall0.959\n",
            ">>> Val: Loss 2.781, Reg 0.000, Acc 0.638, precision: 0.638, recall0.638\n",
            "Epoch 19: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.107, Reg 0.043, Acc 0.974, precision: 0.974, recall0.974\n",
            ">>> Val: Loss 2.715, Reg 0.000, Acc 0.623, precision: 0.623, recall0.623\n",
            "Epoch 20: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.080, Reg 0.043, Acc 0.983, precision: 0.983, recall0.983\n",
            ">>> Val: Loss 2.696, Reg 0.000, Acc 0.619, precision: 0.619, recall0.619\n",
            "Epoch 21: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.060, Reg 0.042, Acc 0.986, precision: 0.986, recall0.986\n",
            ">>> Val: Loss 2.640, Reg 0.000, Acc 0.623, precision: 0.623, recall0.623\n",
            "Epoch 22: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.048, Reg 0.039, Acc 0.990, precision: 0.990, recall0.990\n",
            ">>> Val: Loss 2.564, Reg 0.000, Acc 0.613, precision: 0.613, recall0.613\n",
            "Epoch 23: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.040, Reg 0.037, Acc 0.991, precision: 0.991, recall0.991\n",
            ">>> Val: Loss 2.557, Reg 0.000, Acc 0.613, precision: 0.613, recall0.613\n",
            "Epoch 24: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.033, Reg 0.035, Acc 0.994, precision: 0.994, recall0.994\n",
            ">>> Val: Loss 2.500, Reg 0.000, Acc 0.611, precision: 0.611, recall0.611\n",
            "Epoch 25: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.029, Reg 0.034, Acc 0.995, precision: 0.995, recall0.995\n",
            ">>> Val: Loss 2.512, Reg 0.000, Acc 0.613, precision: 0.613, recall0.613\n",
            "Epoch 26: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.026, Reg 0.033, Acc 0.997, precision: 0.997, recall0.997\n",
            ">>> Val: Loss 2.500, Reg 0.000, Acc 0.608, precision: 0.608, recall0.608\n",
            "Epoch 27: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.022, Reg 0.032, Acc 0.999, precision: 0.999, recall0.999\n",
            ">>> Val: Loss 2.485, Reg 0.000, Acc 0.604, precision: 0.604, recall0.604\n",
            "Epoch 28: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.020, Reg 0.031, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.463, Reg 0.000, Acc 0.602, precision: 0.602, recall0.602\n",
            "Epoch 29: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.018, Reg 0.030, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.467, Reg 0.000, Acc 0.611, precision: 0.611, recall0.611\n",
            "Epoch 30: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.017, Reg 0.029, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.460, Reg 0.000, Acc 0.608, precision: 0.608, recall0.608\n",
            "Epoch 31: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.015, Reg 0.029, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.489, Reg 0.000, Acc 0.603, precision: 0.603, recall0.603\n",
            "Epoch 32: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.014, Reg 0.028, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.444, Reg 0.000, Acc 0.609, precision: 0.609, recall0.609\n",
            "Epoch 33: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.013, Reg 0.027, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.481, Reg 0.000, Acc 0.607, precision: 0.607, recall0.607\n",
            "Epoch 34: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.012, Reg 0.027, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.514, Reg 0.000, Acc 0.614, precision: 0.614, recall0.614\n",
            "Epoch 35: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.012, Reg 0.026, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.486, Reg 0.000, Acc 0.609, precision: 0.609, recall0.609\n",
            "Epoch 36: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.011, Reg 0.026, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.500, Reg 0.000, Acc 0.604, precision: 0.604, recall0.604\n",
            "Epoch 37: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.011, Reg 0.026, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.482, Reg 0.000, Acc 0.606, precision: 0.606, recall0.606\n",
            "Epoch 38: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.011, Reg 0.025, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.486, Reg 0.000, Acc 0.610, precision: 0.610, recall0.610\n",
            "Epoch 39: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.011, Reg 0.025, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.502, Reg 0.000, Acc 0.613, precision: 0.613, recall0.613\n",
            "Epoch 40: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.010, Reg 0.024, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.457, Reg 0.000, Acc 0.616, precision: 0.616, recall0.616\n",
            "Epoch 41: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.010, Reg 0.024, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.472, Reg 0.000, Acc 0.614, precision: 0.614, recall0.614\n",
            "Epoch 42: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.010, Reg 0.024, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.458, Reg 0.000, Acc 0.611, precision: 0.611, recall0.611\n",
            "Epoch 43: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.010, Reg 0.023, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.491, Reg 0.000, Acc 0.610, precision: 0.610, recall0.610\n",
            "Epoch 44: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.010, Reg 0.023, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.465, Reg 0.000, Acc 0.608, precision: 0.608, recall0.608\n",
            "Epoch 45: Best val loss inf, Best val acc 0.6633064516129032\n",
            ">>> Training: Loss 0.010, Reg 0.023, Acc 1.000, precision: 1.000, recall1.000\n",
            ">>> Val: Loss 2.479, Reg 0.000, Acc 0.623, precision: 0.623, recall0.623\n",
            "Epoch 46: Best val loss inf, Best val acc 0.6633064516129032\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 129, in <module>\n",
            "    optim.step(closure)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 113, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/sgd.py\", line 125, in step\n",
            "    loss = closure()\n",
            "  File \"main.py\", line 120, in closure\n",
            "    lossMeter.update(loss.detach().item(), data[0].shape[0])\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%mkdir /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints"
      ],
      "metadata": {
        "id": "O4m8fvzN-oJN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%cp ./saved/model/epoch97_acc_0.762.ckpt /content/drive/MyDrive/Corbin_Adam_PhD_Workspace/corbin_papers/dissertation_proposal/model_checkpoints/CIRCLE/mobilenetv3l/"
      ],
      "metadata": {
        "id": "1hFw2rQB-7np"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}